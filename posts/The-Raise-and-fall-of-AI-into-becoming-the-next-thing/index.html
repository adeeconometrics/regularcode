<!DOCTYPE html><html lang="en-US" ><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><meta name="generator" content="Jekyll v4.3.4" /><meta property="og:title" content="The Rise and Fall of AI into becoming the next Big Thing" /><meta name="author" content="Dave Amiana" /><meta property="og:locale" content="en_US" /><meta name="description" content="In this article, we will talk about the hype and the financial setbacks that the AI community has faced over the years. The challenges and limitations of logic-based AI (Symbolic AI), and probabilistic models (Neural Networks). image source: https://bit.ly/3fXz4x8 Promises of AI The hype in AI research has ever been fuelled by intense optimism so much so that it had overlooked substantial constraints and obstacles that had caused a couple of setbacks to which the field had almost been abandoned by major investors. Briefing for US Vice President Gerald Ford in 1973 on the junction-grammar-based computer translation model. Image source: https://bit.ly/2y7Wgrg. Programs that were developed years after the Dartmouth conference would be able to solve algebraic word problems, prove geometric theorems, and learn the English language [2–3]. Because of this, researchers in the field expressed their optimistic views to the promises of AI, forecasting that a fully intelligent machine would be built in less than 20 years [3]. One of the most notable claims was made by a well-known researcher at the time, Marvin Minsky (1970) who made mention that “from three to eight years we will have a machine with the general intelligence of an average human being” [4] although Minsky believed that he had been misquoted [1]. With their research achievements and increasing business interest, AI research had been funded by the government and granted to fund Minsky and McCarthy’s project $ 2.2 million. There have been pit stops that had caused significant setbacks on AI research AI winter is a period of reduced funding and interest in artificial intelligence research. The Embryo of Artificial Agents Mark I Perceptron machine, the first implementation of the perceptron algorithm. Image Source: https://bit.ly/3ebeHe4. In 1958, American psychologist Frank Rosenblatt invented the perceptron algorithm — which was a form of a binary classifier akin to logistic linear regression. The project was funded by the Office of Naval Research in the United States; the results were promising since the (single-layer) perceptron model implemented in the Mark I Perceptron Machine has been able to perform well in classification tasks — which is regarded as a form of learning. In 1960, Rosenblatt and colleagues were able to show that the perceptron could in finitely many training cycles learn any task that its parameters could embody. The perceptron convergence theorem was proved for single-layer neural nets (Olazaran, 1996). The New York Times documented Rosenblatt’s claims, with his perceptrons (most notably named as Neural Networks), about showcasing that perceptrons would soon be able to beat humans at chess, identify images, and reproduce [9]. At the same time, novel approaches including Symbolic AI have emerged. The basic form of single-layer perceptron has faced significant limitations in recognizing multiple types of patterns. It has been determined that single-layer perceptrons are only capable of learning linearly separable patterns — that is if you can draw a fine line between the apples and oranges the pattern is considered to be linearly separable. Because of this, multi-layer perceptron models were introduced in hopes of finding a more substantial answer to identifying non-linear patterns. Companions, Colleagues, and Critics Bronx High School of Science (1961). Image Source: https://bit.ly/3d0gDpt. Interestingly, the people who contributed significantly to the field both knew each other since high school. Frank Rosenblatt and Marvin Minsky, a notable researcher in Symbolic AI, had studied together at the Bronx High School of Science [10]. Pappert &amp; Minsky’s book entitled Perceptrons: an introduction to computational geometry [11]. In response to Rosenblatt’s claims, Minsky together with his colleague Seymour Pappert had published a book that had been a long-standing controversy in AI. According to Olazaran (1996), the book both acknowledged the strengths while also showing major limitations of the Perceptron models. A series of mathematical proofs have had Rosenblatt’s neural networks bought to a halt. One of the most notable criticisms of single-layer perceptrons is about modeling fundamental gated systems such as the XOR function. However, Minsky &amp; Pappert knew that with multi-layer perceptron models an XOR function can be produced. Because of the miscited content of Perceptrons (the book), the interest and funding to calibrating the other end of research namely Neural Networks came to a significant halt. It was not until the ’80s that the Neural Network research experienced a resurgence. It is also important to note that Neural Network Models require a significant amount of computing power. This was also a reason for investors to shift their interest to what was more promising at the time — Symbolic AI which is intricately built-in with logic. The first AI winter (1974–1980) In the ’70s, AI was subjected to financial setbacks and criticisms; they have failed to engrave their undertakings to production. Researchers had failed to realize the intricacies of their field and the challenges they will have to face in attempts to come up with a solution. Because of this, the funding for AI research was wiped out [3]. Despite the challenges and major setbacks the field has sought, new ideas were explored in logic programming and commonsense reasoning [5]. The problems that the field has faced in the ’70s are as follows: 1. Limited computer power. 2. Intractability and combinatorial explosion. Richard Karp (1972) demonstrated that there are many problems that can only solved in exponential time (referring to Big-O complexity). Finding solutions to these problems require unimaginable amounts of computer time except when the problems are trivial [6]. 3. Commonsense knowledge and reasoning: the program needs to have some idea of what it might be looking at or what it is talking about. This requires that the program know most of the same things about the world that a child does. Researchers soon discovered that this was a truly vast amount of information [1]. 4. Moravec’s paradox. Proving theorems and solving geometry problems is comparatively easy for computers, but a supposedly simple task like recognizing a face or crossing a room without bumping into anything is extremely difficult. This helps explain why research into vision and robotics had made so little progress by the middle 1970s [1]. 5. The frame and qualification problems. AI researchers (like John McCarthy) who used logic discovered that they could not represent ordinary deductions that involved planning or default reasoning without making changes to the structure of logic itself. They developed new logic (like non-monotonic logic and modal logic) to try to solve the problems [7]. The resurgence of 1980–1987 In the 1980s businesses invested in a form of AI program called expert systems — a program that caters queries or solves problems about a specific domain of knowledge using rules of logic. These systems were built from a structured representation of a human expert’s knowledge about a specific domain. The power of these systems comes from the quality of information drawn from the human experts of the field structured by a programmable set of rules. Because of these systems, the Japanese government-funded the AI model with its fifth-generation computer project [8]. The funding for this project cost about $850 million. Their objectives were to write programs and build machines that could carry on conversations, translate languages, interpret pictures, and reason like human beings [1]. By the same time, John Hopfield had his work published about a different form of neural network called the Hopfield Networks — a form of *recurrent neural network* — that could be able to learn and process information entirely differently from the primal form of perceptrons which are essentially a form of a *feed-forward neural network*. The works of Geoffrey Hinton &amp; David Rumelhart which have enabled neural networks to train and learn to model a series of transformation based on their respective parameters a method that is now called backpropagation algorithm [3]. The Hopfield Networks and Backpropagation method has revived the field of Neural Network research. Second AI Winter Due to the hype and promising notions of AI, businesses had been able to take a leap through monetary investments of AI projects; the rise and fall of AI research funding is an indicative pattern of an economic bubble. “The collapse was in the perception of AI by government agencies and investors — the field continued to make advances despite the criticism. Rodney Brooks and Hans Moravec, researchers from the related field of robotics, argued for an entirely new approach to artificial intelligence”. In 1987, the first indication of the economic setback experienced by the AI community was the sudden collapse of the market for specialized AI hardware. An entire industry worth half a billion dollars was demolished overnight [1]. As a consequence, the more expensive Lisp machines had rendered itself obsolete because, with the failure to materialize the promising AI solutions, there was no longer a reason to buy them. Desktop computers such as Apple and IBM started to become more mainstream in production. The Symbolics Lisp Machine. Image source: https://bit.ly/365jYRI. “Eventually the earliest successful expert systems, such as XCON, proved too expensive to maintain. They were difficult to update, they could not learn, they were “brittle” (i.e., they could make grotesque mistakes when given unusual inputs), and they fell prey to problems (such as the qualification problem) that had been identified years earlier. Expert systems proved useful, but only in a few special contexts.” As of 1993, 300 AI companies had shut down, gone bankrupt, or have been acquired effectively ending the first commercial wave of AI. Final Remarks With the grandeur of AI’s promises, businesses have invested tons of resources to bring AI into production and cater to business solutions. However, the young field of AI in the 90’s has had suffered from (1) lack of computing power, (2) premature theoretical grounds, and (3) failure to realise the complexities of their goals to achieve human-level intelligence. In turn, AI winters and momentary recession had taken place to renew and revise long-held conceptions. Long after the field was formalized, there have been a significant amount of challenges that are currently faced in the AI community. Since AI has grown maturely over the ages, the resources and engineering have prompted theories to be made [and tested] in production. This has enabled the almost-forgotten notion perceptrons — because it requires a ton of computing power but thanks to the benefit of Moore’s Law the development has enabled systems to rekindle the promises of perceptron models and lead the field to reach some of its most ambitious goals, some are even deemed to be impossible such as the AlphaGo project, thanks to Deep Learning. Today, the field of AI has ever been expanding to explore the intricacies of intelligent behavior ranging from computer vision, natural language understanding, and agent-based learning (reinforcement learning) among other things. Interestingly, because of the limitation of purely Deep Learning-based models, and purely Symbolic model approach in tackling natural language understanding such as being able to synthetically engineer a system that can not only understand but also discuss and reason about matters of interest the field has been making progress into recalibrating Symbolic AI into adding-up elements of logic and probabilistic reasoning. This particular area of active research endeavor is known as Neuro-symbolic AI. References: [1]. McCorduck, Pamela (2004), Machines Who Think (2nd ed.), Natick, MA: A. K. Peters, Ltd., ISBN 978–1–56881–205–2. [2]. Crevier, Daniel (1993), AI: The Tumultuous Search for Artificial Intelligence, New York, NY: BasicBooks, ISBN 0–465–02997–3. [3]. Russell, Stuart J.; Norvig, Peter (2003), Artificial Intelligence: A Modern Approach (2nd ed.), Upper Saddle River, New Jersey: Prentice Hall, ISBN 0–13–790395–2. [4]. Tag: Marvin Minsky. (2020, May 11). Retrieved May 13, 2020, from https://quoteinvestigator.com/tag/marvin-minsky/ [5]. Crevier, Daniel (1993), AI: The Tumultuous Search for Artificial Intelligence, New York, NY: BasicBooks, ISBN 0–465–02997–3 [6]. Lighthill, Professor Sir James (1973), “Artificial Intelligence: A General Survey”, Artificial Intelligence: a paper symposium, Science Research Council. [7]. McCarthy, John; Hayes, P. J. (1969), “Some philosophical problems from the standpoint of artificial intelligence”, in Meltzer, B. J.; Mitchie, Donald (eds.), Machine Intelligence 4, Edinburgh University Press, pp. 463–502, retrieved 16 October 2008. [8]. Newquist, HP (1994). The Brain Makers: Genius, Ego, And Greed In The Quest For Machines That Think. New York: Macmillan/SAMS. ISBN 978–0–672–30412–5. [9] Olazaran, Mikel (1996). “A Sociological Study of the Official History of the Perceptrons Controversy”. Social Studies of Science. 26 (3): 611–659. doi:10.1177/030631296026003005. JSTOR 285702. [10] Crevier, Daniel (1993), AI: The Tumultuous Search for Artificial Intelligence, New York, NY: BasicBooks, ISBN 0–465–02997–3. [11]. Minsky, M., &amp; Papert, S. A. (2017). Perceptrons: An introduction to computational geometry. MIT press." /><meta property="og:description" content="In this article, we will talk about the hype and the financial setbacks that the AI community has faced over the years. The challenges and limitations of logic-based AI (Symbolic AI), and probabilistic models (Neural Networks). image source: https://bit.ly/3fXz4x8 Promises of AI The hype in AI research has ever been fuelled by intense optimism so much so that it had overlooked substantial constraints and obstacles that had caused a couple of setbacks to which the field had almost been abandoned by major investors. Briefing for US Vice President Gerald Ford in 1973 on the junction-grammar-based computer translation model. Image source: https://bit.ly/2y7Wgrg. Programs that were developed years after the Dartmouth conference would be able to solve algebraic word problems, prove geometric theorems, and learn the English language [2–3]. Because of this, researchers in the field expressed their optimistic views to the promises of AI, forecasting that a fully intelligent machine would be built in less than 20 years [3]. One of the most notable claims was made by a well-known researcher at the time, Marvin Minsky (1970) who made mention that “from three to eight years we will have a machine with the general intelligence of an average human being” [4] although Minsky believed that he had been misquoted [1]. With their research achievements and increasing business interest, AI research had been funded by the government and granted to fund Minsky and McCarthy’s project $ 2.2 million. There have been pit stops that had caused significant setbacks on AI research AI winter is a period of reduced funding and interest in artificial intelligence research. The Embryo of Artificial Agents Mark I Perceptron machine, the first implementation of the perceptron algorithm. Image Source: https://bit.ly/3ebeHe4. In 1958, American psychologist Frank Rosenblatt invented the perceptron algorithm — which was a form of a binary classifier akin to logistic linear regression. The project was funded by the Office of Naval Research in the United States; the results were promising since the (single-layer) perceptron model implemented in the Mark I Perceptron Machine has been able to perform well in classification tasks — which is regarded as a form of learning. In 1960, Rosenblatt and colleagues were able to show that the perceptron could in finitely many training cycles learn any task that its parameters could embody. The perceptron convergence theorem was proved for single-layer neural nets (Olazaran, 1996). The New York Times documented Rosenblatt’s claims, with his perceptrons (most notably named as Neural Networks), about showcasing that perceptrons would soon be able to beat humans at chess, identify images, and reproduce [9]. At the same time, novel approaches including Symbolic AI have emerged. The basic form of single-layer perceptron has faced significant limitations in recognizing multiple types of patterns. It has been determined that single-layer perceptrons are only capable of learning linearly separable patterns — that is if you can draw a fine line between the apples and oranges the pattern is considered to be linearly separable. Because of this, multi-layer perceptron models were introduced in hopes of finding a more substantial answer to identifying non-linear patterns. Companions, Colleagues, and Critics Bronx High School of Science (1961). Image Source: https://bit.ly/3d0gDpt. Interestingly, the people who contributed significantly to the field both knew each other since high school. Frank Rosenblatt and Marvin Minsky, a notable researcher in Symbolic AI, had studied together at the Bronx High School of Science [10]. Pappert &amp; Minsky’s book entitled Perceptrons: an introduction to computational geometry [11]. In response to Rosenblatt’s claims, Minsky together with his colleague Seymour Pappert had published a book that had been a long-standing controversy in AI. According to Olazaran (1996), the book both acknowledged the strengths while also showing major limitations of the Perceptron models. A series of mathematical proofs have had Rosenblatt’s neural networks bought to a halt. One of the most notable criticisms of single-layer perceptrons is about modeling fundamental gated systems such as the XOR function. However, Minsky &amp; Pappert knew that with multi-layer perceptron models an XOR function can be produced. Because of the miscited content of Perceptrons (the book), the interest and funding to calibrating the other end of research namely Neural Networks came to a significant halt. It was not until the ’80s that the Neural Network research experienced a resurgence. It is also important to note that Neural Network Models require a significant amount of computing power. This was also a reason for investors to shift their interest to what was more promising at the time — Symbolic AI which is intricately built-in with logic. The first AI winter (1974–1980) In the ’70s, AI was subjected to financial setbacks and criticisms; they have failed to engrave their undertakings to production. Researchers had failed to realize the intricacies of their field and the challenges they will have to face in attempts to come up with a solution. Because of this, the funding for AI research was wiped out [3]. Despite the challenges and major setbacks the field has sought, new ideas were explored in logic programming and commonsense reasoning [5]. The problems that the field has faced in the ’70s are as follows: 1. Limited computer power. 2. Intractability and combinatorial explosion. Richard Karp (1972) demonstrated that there are many problems that can only solved in exponential time (referring to Big-O complexity). Finding solutions to these problems require unimaginable amounts of computer time except when the problems are trivial [6]. 3. Commonsense knowledge and reasoning: the program needs to have some idea of what it might be looking at or what it is talking about. This requires that the program know most of the same things about the world that a child does. Researchers soon discovered that this was a truly vast amount of information [1]. 4. Moravec’s paradox. Proving theorems and solving geometry problems is comparatively easy for computers, but a supposedly simple task like recognizing a face or crossing a room without bumping into anything is extremely difficult. This helps explain why research into vision and robotics had made so little progress by the middle 1970s [1]. 5. The frame and qualification problems. AI researchers (like John McCarthy) who used logic discovered that they could not represent ordinary deductions that involved planning or default reasoning without making changes to the structure of logic itself. They developed new logic (like non-monotonic logic and modal logic) to try to solve the problems [7]. The resurgence of 1980–1987 In the 1980s businesses invested in a form of AI program called expert systems — a program that caters queries or solves problems about a specific domain of knowledge using rules of logic. These systems were built from a structured representation of a human expert’s knowledge about a specific domain. The power of these systems comes from the quality of information drawn from the human experts of the field structured by a programmable set of rules. Because of these systems, the Japanese government-funded the AI model with its fifth-generation computer project [8]. The funding for this project cost about $850 million. Their objectives were to write programs and build machines that could carry on conversations, translate languages, interpret pictures, and reason like human beings [1]. By the same time, John Hopfield had his work published about a different form of neural network called the Hopfield Networks — a form of *recurrent neural network* — that could be able to learn and process information entirely differently from the primal form of perceptrons which are essentially a form of a *feed-forward neural network*. The works of Geoffrey Hinton &amp; David Rumelhart which have enabled neural networks to train and learn to model a series of transformation based on their respective parameters a method that is now called backpropagation algorithm [3]. The Hopfield Networks and Backpropagation method has revived the field of Neural Network research. Second AI Winter Due to the hype and promising notions of AI, businesses had been able to take a leap through monetary investments of AI projects; the rise and fall of AI research funding is an indicative pattern of an economic bubble. “The collapse was in the perception of AI by government agencies and investors — the field continued to make advances despite the criticism. Rodney Brooks and Hans Moravec, researchers from the related field of robotics, argued for an entirely new approach to artificial intelligence”. In 1987, the first indication of the economic setback experienced by the AI community was the sudden collapse of the market for specialized AI hardware. An entire industry worth half a billion dollars was demolished overnight [1]. As a consequence, the more expensive Lisp machines had rendered itself obsolete because, with the failure to materialize the promising AI solutions, there was no longer a reason to buy them. Desktop computers such as Apple and IBM started to become more mainstream in production. The Symbolics Lisp Machine. Image source: https://bit.ly/365jYRI. “Eventually the earliest successful expert systems, such as XCON, proved too expensive to maintain. They were difficult to update, they could not learn, they were “brittle” (i.e., they could make grotesque mistakes when given unusual inputs), and they fell prey to problems (such as the qualification problem) that had been identified years earlier. Expert systems proved useful, but only in a few special contexts.” As of 1993, 300 AI companies had shut down, gone bankrupt, or have been acquired effectively ending the first commercial wave of AI. Final Remarks With the grandeur of AI’s promises, businesses have invested tons of resources to bring AI into production and cater to business solutions. However, the young field of AI in the 90’s has had suffered from (1) lack of computing power, (2) premature theoretical grounds, and (3) failure to realise the complexities of their goals to achieve human-level intelligence. In turn, AI winters and momentary recession had taken place to renew and revise long-held conceptions. Long after the field was formalized, there have been a significant amount of challenges that are currently faced in the AI community. Since AI has grown maturely over the ages, the resources and engineering have prompted theories to be made [and tested] in production. This has enabled the almost-forgotten notion perceptrons — because it requires a ton of computing power but thanks to the benefit of Moore’s Law the development has enabled systems to rekindle the promises of perceptron models and lead the field to reach some of its most ambitious goals, some are even deemed to be impossible such as the AlphaGo project, thanks to Deep Learning. Today, the field of AI has ever been expanding to explore the intricacies of intelligent behavior ranging from computer vision, natural language understanding, and agent-based learning (reinforcement learning) among other things. Interestingly, because of the limitation of purely Deep Learning-based models, and purely Symbolic model approach in tackling natural language understanding such as being able to synthetically engineer a system that can not only understand but also discuss and reason about matters of interest the field has been making progress into recalibrating Symbolic AI into adding-up elements of logic and probabilistic reasoning. This particular area of active research endeavor is known as Neuro-symbolic AI. References: [1]. McCorduck, Pamela (2004), Machines Who Think (2nd ed.), Natick, MA: A. K. Peters, Ltd., ISBN 978–1–56881–205–2. [2]. Crevier, Daniel (1993), AI: The Tumultuous Search for Artificial Intelligence, New York, NY: BasicBooks, ISBN 0–465–02997–3. [3]. Russell, Stuart J.; Norvig, Peter (2003), Artificial Intelligence: A Modern Approach (2nd ed.), Upper Saddle River, New Jersey: Prentice Hall, ISBN 0–13–790395–2. [4]. Tag: Marvin Minsky. (2020, May 11). Retrieved May 13, 2020, from https://quoteinvestigator.com/tag/marvin-minsky/ [5]. Crevier, Daniel (1993), AI: The Tumultuous Search for Artificial Intelligence, New York, NY: BasicBooks, ISBN 0–465–02997–3 [6]. Lighthill, Professor Sir James (1973), “Artificial Intelligence: A General Survey”, Artificial Intelligence: a paper symposium, Science Research Council. [7]. McCarthy, John; Hayes, P. J. (1969), “Some philosophical problems from the standpoint of artificial intelligence”, in Meltzer, B. J.; Mitchie, Donald (eds.), Machine Intelligence 4, Edinburgh University Press, pp. 463–502, retrieved 16 October 2008. [8]. Newquist, HP (1994). The Brain Makers: Genius, Ego, And Greed In The Quest For Machines That Think. New York: Macmillan/SAMS. ISBN 978–0–672–30412–5. [9] Olazaran, Mikel (1996). “A Sociological Study of the Official History of the Perceptrons Controversy”. Social Studies of Science. 26 (3): 611–659. doi:10.1177/030631296026003005. JSTOR 285702. [10] Crevier, Daniel (1993), AI: The Tumultuous Search for Artificial Intelligence, New York, NY: BasicBooks, ISBN 0–465–02997–3. [11]. Minsky, M., &amp; Papert, S. A. (2017). Perceptrons: An introduction to computational geometry. MIT press." /><link rel="canonical" href="https://adeeconometrics.github.io//posts/The-Raise-and-fall-of-AI-into-becoming-the-next-thing/" /><meta property="og:url" content="https://adeeconometrics.github.io//posts/The-Raise-and-fall-of-AI-into-becoming-the-next-thing/" /><meta property="og:site_name" content="Dave Amiana" /><meta property="og:type" content="article" /><meta property="article:published_time" content="2020-05-27T00:00:00+08:00" /><meta name="twitter:card" content="summary" /><meta property="twitter:title" content="The Rise and Fall of AI into becoming the next Big Thing" /><meta name="twitter:site" content="@iamdeb25" /><meta name="twitter:creator" content="@Dave Amiana" /><meta name="google-site-verification" content="google-site-verification=28bVbRErS2VwJaonXuu3GbqmRlyNvizt6I00B2kQh88" /> <script type="application/ld+json"> {"@context":"https://schema.org","@type":"BlogPosting","author":{"@type":"Person","name":"Dave Amiana"},"dateModified":"2022-10-22T22:11:50+08:00","datePublished":"2020-05-27T00:00:00+08:00","description":"In this article, we will talk about the hype and the financial setbacks that the AI community has faced over the years. The challenges and limitations of logic-based AI (Symbolic AI), and probabilistic models (Neural Networks). image source: https://bit.ly/3fXz4x8 Promises of AI The hype in AI research has ever been fuelled by intense optimism so much so that it had overlooked substantial constraints and obstacles that had caused a couple of setbacks to which the field had almost been abandoned by major investors. Briefing for US Vice President Gerald Ford in 1973 on the junction-grammar-based computer translation model. Image source: https://bit.ly/2y7Wgrg. Programs that were developed years after the Dartmouth conference would be able to solve algebraic word problems, prove geometric theorems, and learn the English language [2–3]. Because of this, researchers in the field expressed their optimistic views to the promises of AI, forecasting that a fully intelligent machine would be built in less than 20 years [3]. One of the most notable claims was made by a well-known researcher at the time, Marvin Minsky (1970) who made mention that “from three to eight years we will have a machine with the general intelligence of an average human being” [4] although Minsky believed that he had been misquoted [1]. With their research achievements and increasing business interest, AI research had been funded by the government and granted to fund Minsky and McCarthy’s project $ 2.2 million. There have been pit stops that had caused significant setbacks on AI research AI winter is a period of reduced funding and interest in artificial intelligence research. The Embryo of Artificial Agents Mark I Perceptron machine, the first implementation of the perceptron algorithm. Image Source: https://bit.ly/3ebeHe4. In 1958, American psychologist Frank Rosenblatt invented the perceptron algorithm — which was a form of a binary classifier akin to logistic linear regression. The project was funded by the Office of Naval Research in the United States; the results were promising since the (single-layer) perceptron model implemented in the Mark I Perceptron Machine has been able to perform well in classification tasks — which is regarded as a form of learning. In 1960, Rosenblatt and colleagues were able to show that the perceptron could in finitely many training cycles learn any task that its parameters could embody. The perceptron convergence theorem was proved for single-layer neural nets (Olazaran, 1996). The New York Times documented Rosenblatt’s claims, with his perceptrons (most notably named as Neural Networks), about showcasing that perceptrons would soon be able to beat humans at chess, identify images, and reproduce [9]. At the same time, novel approaches including Symbolic AI have emerged. The basic form of single-layer perceptron has faced significant limitations in recognizing multiple types of patterns. It has been determined that single-layer perceptrons are only capable of learning linearly separable patterns — that is if you can draw a fine line between the apples and oranges the pattern is considered to be linearly separable. Because of this, multi-layer perceptron models were introduced in hopes of finding a more substantial answer to identifying non-linear patterns. Companions, Colleagues, and Critics Bronx High School of Science (1961). Image Source: https://bit.ly/3d0gDpt. Interestingly, the people who contributed significantly to the field both knew each other since high school. Frank Rosenblatt and Marvin Minsky, a notable researcher in Symbolic AI, had studied together at the Bronx High School of Science [10]. Pappert &amp; Minsky’s book entitled Perceptrons: an introduction to computational geometry [11]. In response to Rosenblatt’s claims, Minsky together with his colleague Seymour Pappert had published a book that had been a long-standing controversy in AI. According to Olazaran (1996), the book both acknowledged the strengths while also showing major limitations of the Perceptron models. A series of mathematical proofs have had Rosenblatt’s neural networks bought to a halt. One of the most notable criticisms of single-layer perceptrons is about modeling fundamental gated systems such as the XOR function. However, Minsky &amp; Pappert knew that with multi-layer perceptron models an XOR function can be produced. Because of the miscited content of Perceptrons (the book), the interest and funding to calibrating the other end of research namely Neural Networks came to a significant halt. It was not until the ’80s that the Neural Network research experienced a resurgence. It is also important to note that Neural Network Models require a significant amount of computing power. This was also a reason for investors to shift their interest to what was more promising at the time — Symbolic AI which is intricately built-in with logic. The first AI winter (1974–1980) In the ’70s, AI was subjected to financial setbacks and criticisms; they have failed to engrave their undertakings to production. Researchers had failed to realize the intricacies of their field and the challenges they will have to face in attempts to come up with a solution. Because of this, the funding for AI research was wiped out [3]. Despite the challenges and major setbacks the field has sought, new ideas were explored in logic programming and commonsense reasoning [5]. The problems that the field has faced in the ’70s are as follows: 1. Limited computer power. 2. Intractability and combinatorial explosion. Richard Karp (1972) demonstrated that there are many problems that can only solved in exponential time (referring to Big-O complexity). Finding solutions to these problems require unimaginable amounts of computer time except when the problems are trivial [6]. 3. Commonsense knowledge and reasoning: the program needs to have some idea of what it might be looking at or what it is talking about. This requires that the program know most of the same things about the world that a child does. Researchers soon discovered that this was a truly vast amount of information [1]. 4. Moravec’s paradox. Proving theorems and solving geometry problems is comparatively easy for computers, but a supposedly simple task like recognizing a face or crossing a room without bumping into anything is extremely difficult. This helps explain why research into vision and robotics had made so little progress by the middle 1970s [1]. 5. The frame and qualification problems. AI researchers (like John McCarthy) who used logic discovered that they could not represent ordinary deductions that involved planning or default reasoning without making changes to the structure of logic itself. They developed new logic (like non-monotonic logic and modal logic) to try to solve the problems [7]. The resurgence of 1980–1987 In the 1980s businesses invested in a form of AI program called expert systems — a program that caters queries or solves problems about a specific domain of knowledge using rules of logic. These systems were built from a structured representation of a human expert’s knowledge about a specific domain. The power of these systems comes from the quality of information drawn from the human experts of the field structured by a programmable set of rules. Because of these systems, the Japanese government-funded the AI model with its fifth-generation computer project [8]. The funding for this project cost about $850 million. Their objectives were to write programs and build machines that could carry on conversations, translate languages, interpret pictures, and reason like human beings [1]. By the same time, John Hopfield had his work published about a different form of neural network called the Hopfield Networks — a form of *recurrent neural network* — that could be able to learn and process information entirely differently from the primal form of perceptrons which are essentially a form of a *feed-forward neural network*. The works of Geoffrey Hinton &amp; David Rumelhart which have enabled neural networks to train and learn to model a series of transformation based on their respective parameters a method that is now called backpropagation algorithm [3]. The Hopfield Networks and Backpropagation method has revived the field of Neural Network research. Second AI Winter Due to the hype and promising notions of AI, businesses had been able to take a leap through monetary investments of AI projects; the rise and fall of AI research funding is an indicative pattern of an economic bubble. “The collapse was in the perception of AI by government agencies and investors — the field continued to make advances despite the criticism. Rodney Brooks and Hans Moravec, researchers from the related field of robotics, argued for an entirely new approach to artificial intelligence”. In 1987, the first indication of the economic setback experienced by the AI community was the sudden collapse of the market for specialized AI hardware. An entire industry worth half a billion dollars was demolished overnight [1]. As a consequence, the more expensive Lisp machines had rendered itself obsolete because, with the failure to materialize the promising AI solutions, there was no longer a reason to buy them. Desktop computers such as Apple and IBM started to become more mainstream in production. The Symbolics Lisp Machine. Image source: https://bit.ly/365jYRI. “Eventually the earliest successful expert systems, such as XCON, proved too expensive to maintain. They were difficult to update, they could not learn, they were “brittle” (i.e., they could make grotesque mistakes when given unusual inputs), and they fell prey to problems (such as the qualification problem) that had been identified years earlier. Expert systems proved useful, but only in a few special contexts.” As of 1993, 300 AI companies had shut down, gone bankrupt, or have been acquired effectively ending the first commercial wave of AI. Final Remarks With the grandeur of AI’s promises, businesses have invested tons of resources to bring AI into production and cater to business solutions. However, the young field of AI in the 90’s has had suffered from (1) lack of computing power, (2) premature theoretical grounds, and (3) failure to realise the complexities of their goals to achieve human-level intelligence. In turn, AI winters and momentary recession had taken place to renew and revise long-held conceptions. Long after the field was formalized, there have been a significant amount of challenges that are currently faced in the AI community. Since AI has grown maturely over the ages, the resources and engineering have prompted theories to be made [and tested] in production. This has enabled the almost-forgotten notion perceptrons — because it requires a ton of computing power but thanks to the benefit of Moore’s Law the development has enabled systems to rekindle the promises of perceptron models and lead the field to reach some of its most ambitious goals, some are even deemed to be impossible such as the AlphaGo project, thanks to Deep Learning. Today, the field of AI has ever been expanding to explore the intricacies of intelligent behavior ranging from computer vision, natural language understanding, and agent-based learning (reinforcement learning) among other things. Interestingly, because of the limitation of purely Deep Learning-based models, and purely Symbolic model approach in tackling natural language understanding such as being able to synthetically engineer a system that can not only understand but also discuss and reason about matters of interest the field has been making progress into recalibrating Symbolic AI into adding-up elements of logic and probabilistic reasoning. This particular area of active research endeavor is known as Neuro-symbolic AI. References: [1]. McCorduck, Pamela (2004), Machines Who Think (2nd ed.), Natick, MA: A. K. Peters, Ltd., ISBN 978–1–56881–205–2. [2]. Crevier, Daniel (1993), AI: The Tumultuous Search for Artificial Intelligence, New York, NY: BasicBooks, ISBN 0–465–02997–3. [3]. Russell, Stuart J.; Norvig, Peter (2003), Artificial Intelligence: A Modern Approach (2nd ed.), Upper Saddle River, New Jersey: Prentice Hall, ISBN 0–13–790395–2. [4]. Tag: Marvin Minsky. (2020, May 11). Retrieved May 13, 2020, from https://quoteinvestigator.com/tag/marvin-minsky/ [5]. Crevier, Daniel (1993), AI: The Tumultuous Search for Artificial Intelligence, New York, NY: BasicBooks, ISBN 0–465–02997–3 [6]. Lighthill, Professor Sir James (1973), “Artificial Intelligence: A General Survey”, Artificial Intelligence: a paper symposium, Science Research Council. [7]. McCarthy, John; Hayes, P. J. (1969), “Some philosophical problems from the standpoint of artificial intelligence”, in Meltzer, B. J.; Mitchie, Donald (eds.), Machine Intelligence 4, Edinburgh University Press, pp. 463–502, retrieved 16 October 2008. [8]. Newquist, HP (1994). The Brain Makers: Genius, Ego, And Greed In The Quest For Machines That Think. New York: Macmillan/SAMS. ISBN 978–0–672–30412–5. [9] Olazaran, Mikel (1996). “A Sociological Study of the Official History of the Perceptrons Controversy”. Social Studies of Science. 26 (3): 611–659. doi:10.1177/030631296026003005. JSTOR 285702. [10] Crevier, Daniel (1993), AI: The Tumultuous Search for Artificial Intelligence, New York, NY: BasicBooks, ISBN 0–465–02997–3. [11]. Minsky, M., &amp; Papert, S. A. (2017). Perceptrons: An introduction to computational geometry. MIT press.","headline":"The Rise and Fall of AI into becoming the next Big Thing","mainEntityOfPage":{"@type":"WebPage","@id":"https://adeeconometrics.github.io//posts/The-Raise-and-fall-of-AI-into-becoming-the-next-thing/"},"url":"https://adeeconometrics.github.io//posts/The-Raise-and-fall-of-AI-into-becoming-the-next-thing/"}</script><title>The Rise and Fall of AI into becoming the next Big Thing | Dave Amiana</title><link rel="apple-touch-icon" sizes="180x180" href="/assets/img/favicons/apple-touch-icon.png"><link rel="icon" type="image/png" sizes="32x32" href="/assets/img/favicons/favicon-32x32.png"><link rel="icon" type="image/png" sizes="16x16" href="/assets/img/favicons/favicon-16x16.png"><link rel="manifest" href="/assets/img/favicons/site.webmanifest"><link rel="shortcut icon" href="/assets/img/favicons/favicon.ico"><meta name="apple-mobile-web-app-title" content="Dave Amiana"><meta name="application-name" content="Dave Amiana"><meta name="msapplication-TileColor" content="#da532c"><meta name="msapplication-config" content="/assets/img/favicons/browserconfig.xml"><meta name="theme-color" content="#ffffff"><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin="anonymous"><link rel="dns-prefetch" href="https://fonts.gstatic.com"><link rel="preconnect" href="https://www.google-analytics.com" crossorigin="use-credentials"><link rel="dns-prefetch" href="https://www.google-analytics.com"><link rel="preconnect" href="https://www.googletagmanager.com" crossorigin="anonymous"><link rel="dns-prefetch" href="https://www.googletagmanager.com"><link rel="preconnect" href="https://cdn.jsdelivr.net"><link rel="dns-prefetch" href="https://cdn.jsdelivr.net"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.0.0/dist/css/bootstrap.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.11.2/css/all.min.css"><link rel="stylesheet" href="/assets/css/style.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@1.0.1/dist/bootstrap-toc.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/magnific-popup@1.1.0/dist/magnific-popup.min.css"> <script src="https://cdn.jsdelivr.net/npm/jquery@3/dist/jquery.min.js"></script> <script defer src="https://cdn.jsdelivr.net/combine/npm/popper.js@1.15.0,npm/bootstrap@4/dist/js/bootstrap.min.js"></script> <script async src="https://cdn.jsdelivr.net/combine/npm/lozad/dist/lozad.min.js,npm/magnific-popup@1/dist/jquery.magnific-popup.min.js"></script> <script defer src="/assets/js/dist/post.min.js"></script> <script> /* see: <https://docs.mathjax.org/en/latest/options/input/tex.html#tex-options> */ MathJax = { tex: { inlineMath: [ /* start/end delimiter pairs for in-line math */ ['$','$'], ['\\(','\\)'] ], displayMath: [ /* start/end delimiter pairs for display math */ ['$$', '$$'], ['\\[', '\\]'] ] } }; </script> <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script type="text/javascript" id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"> </script> <script defer src="/app.js"></script> <script defer src="https://www.googletagmanager.com/gtag/js?id=G-0M61FBNQ0K"></script> <script> document.addEventListener("DOMContentLoaded", function(event) { window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'G-0M61FBNQ0K'); }); </script><body data-spy="scroll" data-target="#toc"><div id="sidebar" class="d-flex flex-column align-items-end"><div class="profile-wrapper text-center"><div id="avatar"> <a href="/" alt="avatar" class="mx-auto"> <img src="/assets/img/favicons/profile-picture.jpg" alt="avatar" onerror="this.style.display='none'"> </a></div><div class="site-title mt-3"> <a href="/">Dave Amiana</a></div><div class="site-subtitle font-italic">Open-source and Enterprise Software Developer</div></div><ul class="w-100"><li class="nav-item"> <a href="/" class="nav-link"> <i class="fa-fw fas fa-home ml-xl-3 mr-xl-3 unloaded"></i> <span>HOME</span> </a><li class="nav-item"> <a href="/categories/" class="nav-link"> <i class="fa-fw fas fa-stream ml-xl-3 mr-xl-3 unloaded"></i> <span>CATEGORIES</span> </a><li class="nav-item"> <a href="/tags/" class="nav-link"> <i class="fa-fw fas fa-tag ml-xl-3 mr-xl-3 unloaded"></i> <span>TAGS</span> </a><li class="nav-item"> <a href="/archives/" class="nav-link"> <i class="fa-fw fas fa-archive ml-xl-3 mr-xl-3 unloaded"></i> <span>ARCHIVES</span> </a><li class="nav-item"> <a href="/about/" class="nav-link"> <i class="fa-fw fas fa-info-circle ml-xl-3 mr-xl-3 unloaded"></i> <span>ABOUT</span> </a></ul><div class="sidebar-bottom mt-auto d-flex flex-wrap justify-content-center"> <a href="https://github.com/adeeconometrics" aria-label="github" class="order-3" target="_blank" rel="noopener"> <i class="fab fa-github-alt"></i> </a> <a href="https://www.linkedin.com/in/dave-amiana/" aria-label="linkedin" class="order-4" target="_blank" rel="noopener"> <i class="fab fa-linkedin"></i> </a> <a href=" javascript:location.href = 'mailto:' + ['amiana.dave','gmail.com'].join('@')" aria-label="email" class="order-5" > <i class="fas fa-envelope"></i> </a> <span id="mode-toggle-wrapper" class="order-1"> <i class="mode-toggle fas fa-adjust"></i> <script type="text/javascript"> class ModeToggle { static get MODE_KEY() { return "mode"; } static get DARK_MODE() { return "dark"; } static get LIGHT_MODE() { return "light"; } constructor() { if (this.hasMode) { if (this.isDarkMode) { if (!this.isSysDarkPrefer) { this.setDark(); } } else { if (this.isSysDarkPrefer) { this.setLight(); } } } var self = this; /* always follow the system prefers */ this.sysDarkPrefers.addListener(function() { if (self.hasMode) { if (self.isDarkMode) { if (!self.isSysDarkPrefer) { self.setDark(); } } else { if (self.isSysDarkPrefer) { self.setLight(); } } self.clearMode(); } self.updateMermaid(); }); } /* constructor() */ setDark() { $('html').attr(ModeToggle.MODE_KEY, ModeToggle.DARK_MODE); sessionStorage.setItem(ModeToggle.MODE_KEY, ModeToggle.DARK_MODE); } setLight() { $('html').attr(ModeToggle.MODE_KEY, ModeToggle.LIGHT_MODE); sessionStorage.setItem(ModeToggle.MODE_KEY, ModeToggle.LIGHT_MODE); } clearMode() { $('html').removeAttr(ModeToggle.MODE_KEY); sessionStorage.removeItem(ModeToggle.MODE_KEY); } get sysDarkPrefers() { return window.matchMedia("(prefers-color-scheme: dark)"); } get isSysDarkPrefer() { return this.sysDarkPrefers.matches; } get isDarkMode() { return this.mode == ModeToggle.DARK_MODE; } get isLightMode() { return this.mode == ModeToggle.LIGHT_MODE; } get hasMode() { return this.mode != null; } get mode() { return sessionStorage.getItem(ModeToggle.MODE_KEY); } /* get the current mode on screen */ get modeStatus() { if (this.isDarkMode || (!this.hasMode && this.isSysDarkPrefer) ) { return ModeToggle.DARK_MODE; } else { return ModeToggle.LIGHT_MODE; } } updateMermaid() { if (typeof mermaid !== "undefined") { let expectedTheme = (this.modeStatus === ModeToggle.DARK_MODE? "dark" : "default"); let config = { theme: expectedTheme }; /* re-render the SVG › <https://github.com/mermaid-js/mermaid/issues/311#issuecomment-332557344> */ $(".mermaid").each(function() { let svgCode = $(this).prev().children().html(); $(this).removeAttr("data-processed"); $(this).html(svgCode); }); mermaid.initialize(config); mermaid.init(undefined, ".mermaid"); } } flipMode() { if (this.hasMode) { if (this.isSysDarkPrefer) { if (this.isLightMode) { this.clearMode(); } else { this.setLight(); } } else { if (this.isDarkMode) { this.clearMode(); } else { this.setDark(); } } } else { if (this.isSysDarkPrefer) { this.setLight(); } else { this.setDark(); } } this.updateMermaid(); } /* flipMode() */ } /* ModeToggle */ let toggle = new ModeToggle(); $(".mode-toggle").click(function() { toggle.flipMode(); }); </script> </span></div></div><div id="topbar-wrapper" class="row justify-content-center topbar-down"><div id="topbar" class="col-11 d-flex h-100 align-items-center justify-content-between"> <span id="breadcrumb"> <span> <a href="/"> Posts </a> </span> <span>The Rise and Fall of AI into becoming the next Big Thing</span> </span> <i id="sidebar-trigger" class="fas fa-bars fa-fw"></i><div id="topbar-title"> Post</div><i id="search-trigger" class="fas fa-search fa-fw"></i> <span id="search-wrapper" class="align-items-center"> <i class="fas fa-search fa-fw"></i> <input class="form-control" id="search-input" type="search" aria-label="search" autocomplete="off" placeholder="Search..."> <i class="fa fa-times-circle fa-fw" id="search-cleaner"></i> </span> <span id="search-cancel" >Cancel</span></div></div><div id="main-wrapper"><div id="main"><div class="row"><div id="post-wrapper" class="col-12 col-lg-11 col-xl-8"><div class="post pl-1 pr-1 pl-sm-2 pr-sm-2 pl-md-4 pr-md-4"><h1 data-toc-skip>The Rise and Fall of AI into becoming the next Big Thing</h1><div class="post-meta text-muted d-flex flex-column"><div> <span class="semi-bold"> Dave Amiana </span> <span class="timeago " data-toggle="tooltip" data-placement="bottom" title="Wed, May 27, 2020, 12:00 AM +0800" prep="on" > May 27, 2020 <i class="unloaded">2020-05-27T00:00:00+08:00</i> </span></div><div> <span> <span class="timeago lastmod" data-toggle="tooltip" data-placement="bottom" title="Sat, Oct 22, 2022, 10:11 PM +0800" prefix="Updated " > Oct 22, 2022 <i class="unloaded">2022-10-22T22:11:50+08:00</i> </span> </span> <span class="readtime" data-toggle="tooltip" data-placement="bottom" title="2070 words">11 min</span></div></div><div class="post-content"><p>In this article, we will talk about the hype and the financial setbacks that the AI community has faced over the years. The challenges and limitations of logic-based AI (Symbolic AI), and probabilistic models (Neural Networks).</p><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://miro.medium.com/max/702/0*HXDPpF8qdywpuGQf.jpg" alt="img" /></p><p>image source: https://bit.ly/3fXz4x8</p><h2 id="promises-of-ai">Promises of AI</h2><p>The hype in AI research has ever been fuelled by intense optimism so much so that it had overlooked substantial constraints and obstacles that had caused a couple of setbacks to which the field had almost been abandoned by major investors.</p><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://miro.medium.com/max/660/0*3eDaaOuKTgzhYyzo.jpg" alt="img" /></p><p>Briefing for US Vice President <a href="https://en.wikipedia.org/wiki/Gerald_Ford">Gerald Ford</a> in 1973 on the <a href="https://en.wikipedia.org/wiki/Junction_Grammar">junction-grammar</a>-based computer translation model. Image source: https://bit.ly/2y7Wgrg.</p><p>Programs that were developed years after the Dartmouth conference would be able to solve algebraic word problems, prove geometric theorems, and learn the English language [2–3]. Because of this, researchers in the field expressed their optimistic views to the promises of AI, <em>forecasting that a fully intelligent machine would be built in less than 20 years</em> [3]. One of the most notable claims was made by a well-known researcher at the time, Marvin Minsky (1970) who made mention that “<em>from three to eight years we will have a machine with the general intelligence of an average human being</em>” [4] although Minsky believed that he had been misquoted [1].</p><p>With their research achievements and increasing business interest, AI research had been funded by the government and granted to fund Minsky and McCarthy’s project $ 2.2 million.</p><p>There have been pit stops that had caused significant setbacks on AI research</p><blockquote><p>AI winter is a period of reduced funding and interest in <a href="https://en.wikipedia.org/wiki/Artificial_intelligence">artificial intelligence</a> research.</p></blockquote><h1 id="the-embryo-of-artificial-agents">The Embryo of Artificial Agents</h1><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://miro.medium.com/max/314/0*thjed3cXC0WfNh1G.jpeg" alt="img" /></p><p>Mark I Perceptron machine, the first implementation of the perceptron algorithm. Image Source: https://bit.ly/3ebeHe4.</p><p>In 1958, American psychologist <strong>Frank Rosenblatt</strong> invented the <strong>perceptron</strong> algorithm — which was a form of a binary classifier akin to <strong>logistic linear regression</strong>. The project was funded by the Office of Naval Research in the United States; the results were promising since the (single-layer) perceptron model implemented in the <strong>Mark I Perceptron Machine</strong> has been able to perform well in classification tasks — which is regarded as a form of learning.</p><blockquote><p>In 1960, Rosenblatt and colleagues were able to show that the perceptron could in finitely many training cycles learn any task that its parameters could embody. The perceptron convergence theorem was proved for single-layer neural nets (Olazaran, 1996).</p></blockquote><p>The New York Times documented Rosenblatt’s claims, with his perceptrons (most notably named as <strong>Neural Networks)</strong>, about showcasing that perceptrons would soon be able to beat humans at chess, identify images, and <em>reproduce</em> [9]<em>.</em> At the same time, novel approaches including <strong>Symbolic AI</strong> have emerged.</p><p>The basic form of <strong>single-layer perceptron</strong> has faced significant limitations in recognizing multiple types of patterns. It has been determined that single-layer perceptrons are only capable of learning linearly separable patterns — that is if you can draw a fine line between the <em>apples and oranges</em> the pattern is considered to be linearly separable. Because of this, <strong>multi-layer perceptron</strong> models were introduced in hopes of finding a more substantial answer to identifying non-linear patterns.</p><h2 id="companions-colleagues-and-critics">Companions, Colleagues, and Critics</h2><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://miro.medium.com/max/770/0*8Dm7eQdsOUie8nBA.jpg" alt="img" /></p><p>Bronx High School of Science (1961). Image Source: https://bit.ly/3d0gDpt.</p><p>Interestingly, the people who contributed significantly to the field both knew each other since high school. <strong>Frank Rosenblatt</strong> and <strong>Marvin Minsky</strong>, a notable researcher in Symbolic AI, had studied together at the Bronx High School of Science [10].</p><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://miro.medium.com/max/770/0*a4Vz3oaWyOgzWbAJ.png" alt="img" /></p><p>Pappert &amp; Minsky’s book entitled Perceptrons: an introduction to computational geometry [11].</p><p>In response to Rosenblatt’s claims, Minsky together with his colleague Seymour Pappert had published a book that had been a long-standing controversy in AI. According to Olazaran (1996), the book both acknowledged the strengths while also showing major limitations of the Perceptron models. A series of mathematical proofs have had Rosenblatt’s neural networks bought to a halt. One of the most notable criticisms of single-layer perceptrons is about modeling fundamental gated systems such as the XOR function. However, Minsky &amp; Pappert knew that with multi-layer perceptron models an XOR function can be produced.</p><blockquote><p><strong>Because of the miscited content of Perceptrons (the book)</strong>, the interest and funding to calibrating the other end of research namely Neural Networks came to a significant halt. It was not until the ’80s that the Neural Network research experienced a resurgence.</p></blockquote><p>It is also important to note that Neural Network Models require a significant amount of computing power. This was also a reason for investors to shift their interest to what was more promising at the time — Symbolic AI which is intricately built-in with logic.</p><h2 id="the-first-ai-winter-19741980">The first AI winter (1974–1980)</h2><p>In the ’70s, AI was subjected to financial setbacks and criticisms; they have failed to engrave their undertakings to production. Researchers had failed to realize the intricacies of their field and the challenges they will have to face in attempts to come up with a solution. Because of this, the funding for AI research was wiped out [3]. Despite the challenges and major setbacks the field has sought, new ideas were explored in logic programming and commonsense reasoning [5]. The problems that the field has faced in the ’70s are as follows:</p><blockquote><p><em>1.</em> Limited computer power.</p><p><em>2.</em> Intractability and combinatorial explosion. Richard Karp (1972) demonstrated that there are many problems that can only solved in exponential time (referring to Big-O complexity). <em>Finding solutions to these problems require unimaginable amounts of computer time except when the problems are trivial</em> [6].</p><p><em>3.</em> Commonsense knowledge and reasoning: <em>the program needs to have some idea of what it might be looking at or what it is talking about. This requires that the program know most of the same things about the world that a child does. Researchers soon discovered that this was a truly vast amount of information</em> [1].</p><p><em>4.</em> Moravec’s paradox. <em>Proving theorems and solving geometry problems is comparatively easy for computers, but a supposedly simple task like recognizing a face or crossing a room without bumping into anything is extremely difficult. This helps explain why research into vision and robotics had made so little progress by the middle 1970</em>s [1].</p><p><em>5.</em> The frame and qualification problems. <em>AI researchers (like John McCarthy) who used logic discovered that they could not represent ordinary deductions that involved planning or default reasoning without making changes to the structure of logic itself. They developed new logic (like non-monotonic logic and modal logic) to try to solve the problems</em> [7].</p></blockquote><h2 id="the-resurgence-of-19801987">The resurgence of 1980–1987</h2><p>In the 1980s businesses invested in a form of AI program called <em>expert systems</em> — a program that caters queries or solves problems about a specific domain of knowledge using rules of logic. These systems were built from a structured representation of a human expert’s knowledge about a specific domain. The power of these systems comes from the quality of information drawn from the human experts of the field structured by a programmable set of rules.</p><p>Because of these systems, the Japanese government-funded the AI model with its fifth-generation computer project [8]. The funding for this project cost about $850 million. <em>Their objectives were to write programs and build machines that could carry on conversations, translate languages, interpret pictures, and reason like human beings</em> [1].</p><p>By the same time, <strong>John Hopfield</strong> had his work published about a different form of neural network called the <strong>Hopfield Networks</strong> — a form of <strong>*recurrent neural network*</strong> — that could be able to learn and process information entirely differently from the primal form of perceptrons which are essentially a form of a <strong>*feed-forward neural network*</strong>.</p><p>The works of <strong>Geoffrey Hinton</strong> &amp; <strong>David Rumelhart</strong> which have enabled neural networks to train and learn to model a series of transformation based on their respective parameters a method that is now called <strong>backpropagation algorithm</strong> [3]<strong>.</strong></p><p>The Hopfield Networks and Backpropagation method has revived the field of Neural Network research.</p><h2 id="second-ai-winter">Second AI Winter</h2><p>Due to the hype and promising notions of AI, businesses had been able to take a leap through monetary investments of AI projects; the rise and fall of AI research funding is an indicative pattern of an <a href="https://bit.ly/3fXzALx">economic bubble</a>.</p><blockquote><p>“The collapse was in the perception of AI by government agencies and investors — the field continued to make advances despite the criticism. Rodney Brooks and Hans Moravec, researchers from the related field of robotics, argued for an entirely new approach to artificial intelligence”.</p></blockquote><p>In 1987, the first indication of the economic setback experienced by the AI community was the sudden collapse of the market for specialized AI hardware. <em>An entire industry worth half a billion dollars was demolished overnight</em> [1]. As a consequence, the more expensive Lisp machines had rendered itself obsolete because, with the failure to materialize the promising AI solutions, there was no longer a reason to buy them. Desktop computers such as Apple and IBM started to become more mainstream in production.</p><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://miro.medium.com/max/692/0*gmsL8Uasj4qx_kvB.png" alt="img" /></p><p>The Symbolics Lisp Machine. Image source: https://bit.ly/365jYRI.</p><blockquote><p>“Eventually the earliest successful expert systems, such as XCON, proved too expensive to maintain. They were difficult to update, they could not learn, they were “brittle” (i.e., they could make grotesque mistakes when given unusual inputs), and they fell prey to problems (such as the qualification problem) that had been identified years earlier. Expert systems proved useful, but only in a few special contexts.”</p></blockquote><p>As of 1993, 300 AI companies had shut down, gone bankrupt, or have been acquired effectively ending the first commercial wave of AI.</p><h1 id="final-remarks">Final Remarks</h1><p>With the grandeur of AI’s promises, businesses have invested tons of resources to bring AI into production and cater to business solutions. However, the young field of AI in the 90’s has had suffered from (1) lack of computing power, (2) premature theoretical grounds, and (3) failure to realise the complexities of their goals to achieve human-level intelligence. In turn, AI winters and momentary recession had taken place to renew and revise long-held conceptions.</p><p>Long after the field was formalized, there have been a significant amount of challenges that are currently faced in the AI community. Since AI has grown maturely over the ages, the resources and engineering have prompted theories to be made [and tested] in production. This has enabled the almost-forgotten notion perceptrons — because it requires a ton of computing power but thanks to the benefit of Moore’s Law the development has enabled systems to rekindle the promises of perceptron models and lead the field to reach some of its most ambitious goals, some are even deemed to be impossible such as the <a href="https://bit.ly/3dRY72L">AlphaGo</a> project, thanks to <a href="https://bit.ly/2X8Ne5Z">Deep Learning</a>. Today, the field of AI has ever been expanding to explore the intricacies of <em>intelligent behavior</em> ranging from <strong>computer vision</strong>, <strong>natural language understanding</strong>, and <strong>agent-based learning</strong> (reinforcement learning) among other things.</p><p>Interestingly, because of the limitation of purely Deep Learning-based models, and purely Symbolic model approach in tackling natural language understanding such as being able to synthetically engineer a system that can not only understand but also discuss and reason about matters of interest the field has been making progress into recalibrating Symbolic AI into adding-up elements of logic and probabilistic reasoning. This particular area of active research endeavor is known as <a href="https://bit.ly/3ghpWDF"><strong>Neuro-symbolic AI</strong></a>.</p><h2 id="references"><strong>References:</strong></h2><p>[1]. McCorduck, Pamela (2004), Machines Who Think (2nd ed.), Natick, MA: A. K. Peters, Ltd., ISBN 978–1–56881–205–2.</p><p>[2]. Crevier, Daniel (1993), AI: The Tumultuous Search for Artificial Intelligence, New York, NY: BasicBooks, ISBN 0–465–02997–3.</p><p>[3]. Russell, Stuart J.; Norvig, Peter (2003), Artificial Intelligence: A Modern Approach (2nd ed.), Upper Saddle River, New Jersey: Prentice Hall, ISBN 0–13–790395–2.</p><p>[4]. Tag: Marvin Minsky. (2020, May 11). Retrieved May 13, 2020, from https://quoteinvestigator.com/tag/marvin-minsky/</p><p>[5]. Crevier, Daniel (1993), AI: The Tumultuous Search for Artificial Intelligence, New York, NY: BasicBooks, ISBN 0–465–02997–3</p><p>[6]. Lighthill, Professor Sir James (1973), “Artificial Intelligence: A General Survey”, Artificial Intelligence: a paper symposium, Science Research Council.</p><p>[7]. McCarthy, John; Hayes, P. J. (1969), “Some philosophical problems from the standpoint of artificial intelligence”, in Meltzer, B. J.; Mitchie, Donald (eds.), Machine Intelligence 4, Edinburgh University Press, pp. 463–502, retrieved 16 October 2008.</p><p>[8]. Newquist, HP (1994). The Brain Makers: Genius, Ego, And Greed In The Quest For Machines That Think. New York: Macmillan/SAMS. ISBN 978–0–672–30412–5.</p><p>[9] Olazaran, Mikel (1996). “A Sociological Study of the Official History of the Perceptrons Controversy”. <em>Social Studies of Science</em>. <strong>26</strong> (3): 611–659. <a href="https://en.wikipedia.org/wiki/Doi_(identifier)">doi</a>:<a href="https://doi.org/10.1177%2F030631296026003005">10.1177/030631296026003005</a>. <a href="https://en.wikipedia.org/wiki/JSTOR_(identifier)">JSTOR</a> <a href="https://www.jstor.org/stable/285702">285702</a>.</p><p>[10] <a href="https://en.wikipedia.org/wiki/Daniel_Crevier">Crevier, Daniel</a> (1993), <em>AI: The Tumultuous Search for Artificial Intelligence</em>, New York, NY: BasicBooks, <a href="https://en.wikipedia.org/wiki/ISBN_(identifier)">ISBN</a> <a href="https://en.wikipedia.org/wiki/Special:BookSources/0-465-02997-3">0–465–02997–3</a>.</p><p>[11]. Minsky, M., &amp; Papert, S. A. (2017). <em>Perceptrons: An introduction to computational geometry</em>. MIT press.</p></div><div class="post-tail-wrapper text-muted"><div class="post-meta mb-3"> <i class="far fa-folder-open fa-fw mr-1"></i> <a href='/categories/computer-science/'>Computer Science</a>, <a href='/categories/ai/'>AI</a></div><div class="post-tags"> <i class="fa fa-tags fa-fw mr-1"></i> <a href="/tags/computer-science/" class="post-tag no-text-decoration" >Computer Science</a> <a href="/tags/ai/" class="post-tag no-text-decoration" >AI</a></div><div class="post-tail-bottom d-flex justify-content-between align-items-center mt-3 pt-5 pb-2"><div class="license-wrapper"> This post is licensed under <a href="https://creativecommons.org/licenses/by/4.0/">CC BY 4.0</a> by the author.</div><div class="share-wrapper"> <span class="share-label text-muted mr-1">Share</span> <span class="share-icons"> <a href="https://twitter.com/intent/tweet?text=The Rise and Fall of AI into becoming the next Big Thing - Dave Amiana&url=https://adeeconometrics.github.io//posts/The-Raise-and-fall-of-AI-into-becoming-the-next-thing/" data-toggle="tooltip" data-placement="top" title="Twitter" target="_blank" rel="noopener" aria-label="Twitter"> <i class="fa-fw fab fa-twitter"></i> </a> <a href="https://www.facebook.com/sharer/sharer.php?title=The Rise and Fall of AI into becoming the next Big Thing - Dave Amiana&u=https://adeeconometrics.github.io//posts/The-Raise-and-fall-of-AI-into-becoming-the-next-thing/" data-toggle="tooltip" data-placement="top" title="Facebook" target="_blank" rel="noopener" aria-label="Facebook"> <i class="fa-fw fab fa-facebook-square"></i> </a> <a href="https://telegram.me/share?text=The Rise and Fall of AI into becoming the next Big Thing - Dave Amiana&url=https://adeeconometrics.github.io//posts/The-Raise-and-fall-of-AI-into-becoming-the-next-thing/" data-toggle="tooltip" data-placement="top" title="Telegram" target="_blank" rel="noopener" aria-label="Telegram"> <i class="fa-fw fab fa-telegram"></i> </a> <i class="fa-fw fas fa-link small" onclick="copyLink()" data-toggle="tooltip" data-placement="top" title="Copy link"></i> </span></div></div></div></div></div><div id="panel-wrapper" class="col-xl-3 pl-2 text-muted topbar-down"><div class="access"><div id="access-lastmod" class="post"> <span>Recent Update</span><ul class="post-content pl-0 pb-1 ml-1 mt-2"><li><a href="/posts/On-Pointer-Types/">On Pointer Types</a><li><a href="/posts/Pointers-and-References-Design-Goals-and-Use-Cases/">Pointers and References: Design Goals and Use Cases</a><li><a href="/posts/Unique-Reference/">Unique References</a><li><a href="/posts/Shared-Reference/">Shared References</a><li><a href="/posts/Weak-Reference/">Weak References</a></ul></div><div id="access-tags"> <span>Trending Tags</span><div class="d-flex flex-wrap mt-3 mb-1 mr-3"> <a class="post-tag" href="/tags/computer-science/">Computer Science</a> <a class="post-tag" href="/tags/programming/">programming</a> <a class="post-tag" href="/tags/c/">C++</a> <a class="post-tag" href="/tags/data-structures/">Data Structures</a> <a class="post-tag" href="/tags/programming/">Programming</a> <a class="post-tag" href="/tags/algorithms/">Algorithms</a> <a class="post-tag" href="/tags/ownership-semantics/">Ownership Semantics</a> <a class="post-tag" href="/tags/ai/">AI</a> <a class="post-tag" href="/tags/c/">C#</a> <a class="post-tag" href="/tags/java/">Java</a></div></div></div><script src="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@1.0.1/dist/bootstrap-toc.min.js"></script><div id="toc-wrapper" class="pl-0 pr-4 mb-5"> <span class="pl-3 pt-2 mb-2">Contents</span><nav id="toc" data-toggle="toc"></nav></div></div></div><div class="row"><div class="col-12 col-lg-11 col-xl-8"><div id="post-extend-wrapper" class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-md-4 pr-md-4"><div id="related-posts" class="mt-5 mb-2 mb-sm-4"><h3 class="pt-2 mt-1 mb-4 ml-1" data-toc-skip>Further Reading</h3><div class="card-deck mb-4"><div class="card"> <a href="/posts/AI-From-Imagination-to-Abstraction/"><div class="card-body"> <span class="timeago small" > May 14, 2020 <i class="unloaded">2020-05-14T00:00:00+08:00</i> </span><h3 class="pt-0 mt-1 mb-3" data-toc-skip>AI: From Imagination to Abstraction</h3><div class="text-muted small"><p> Development is an iterative process. Photo by NOAA on Unsplash This article revisits the mystical elements that have formed our conception of artificial minds and intelligent systems from myths ...</p></div></div></a></div><div class="card"> <a href="/posts/Stable-Diffusion-From-First-Principles/"><div class="card-body"> <span class="timeago small" > Oct 22, 2022 <i class="unloaded">2022-10-22T00:00:00+08:00</i> </span><h3 class="pt-0 mt-1 mb-3" data-toc-skip>Stable Diffusion From First Principles</h3><div class="text-muted small"><p> An Overview of Generative Modeling Framework Generative models have been successfully used for computer vision tasks such as image super-resolution (Saharia et. al., 2021), text-to-image synthesis...</p></div></div></a></div><div class="card"> <a href="/posts/On-Pointer-Types/"><div class="card-body"> <span class="timeago small" > Aug 12, 2021 <i class="unloaded">2021-08-12T00:00:00+08:00</i> </span><h3 class="pt-0 mt-1 mb-3" data-toc-skip>On Pointer Types</h3><div class="text-muted small"><p> In this article, I aim to introduce the concept and motivation behind using pointers. There are breeds of C++ developers that only use smart pointers for safety reasons, others that only use raw po...</p></div></div></a></div></div></div><div class="post-navigation d-flex justify-content-between"> <a href="/posts/AI-From-Imagination-to-Abstraction/" class="btn btn-outline-primary" prompt="Older"><p>AI: From Imagination to Abstraction</p></a> <a href="/posts/Making-Sense-of-Algorithms/" class="btn btn-outline-primary" prompt="Newer"><p>Making Sense of Algorithms: General Perspective</p></a></div></div></div></div><footer class="d-flex w-100 justify-content-center"><div class="d-flex justify-content-between align-items-center text-muted"><div class="footer-left"><p class="mb-0"> © 2024 <a href="https://twitter.com/iamdeb25">Dave Amiana</a>.</p></div><div class="footer-right"><p class="mb-0"> Powered by <a href="https://jekyllrb.com" target="_blank" rel="noopener">Jekyll</a> with <a href="https://github.com/cotes2020/jekyll-theme-chirpy" target="_blank" rel="noopener">Chirpy</a> theme.</p></div></div></footer></div><div id="search-result-wrapper" class="d-flex justify-content-center unloaded"><div class="col-12 col-sm-11 post-content"><div id="search-hints"><h4 class="text-muted mb-4">Trending Tags</h4><a class="post-tag" href="/tags/computer-science/">Computer Science</a> <a class="post-tag" href="/tags/programming/">programming</a> <a class="post-tag" href="/tags/c/">C++</a> <a class="post-tag" href="/tags/data-structures/">Data Structures</a> <a class="post-tag" href="/tags/programming/">Programming</a> <a class="post-tag" href="/tags/algorithms/">Algorithms</a> <a class="post-tag" href="/tags/ownership-semantics/">Ownership Semantics</a> <a class="post-tag" href="/tags/ai/">AI</a> <a class="post-tag" href="/tags/c/">C#</a> <a class="post-tag" href="/tags/java/">Java</a></div><div id="search-results" class="d-flex flex-wrap justify-content-center text-muted mt-3"></div></div></div></div><div id="mask"></div><a id="back-to-top" href="#" aria-label="back-to-top" class="btn btn-lg btn-box-shadow" role="button"> <i class="fas fa-angle-up"></i> </a> <script src="https://cdn.jsdelivr.net/npm/simple-jekyll-search@1.7.3/dest/simple-jekyll-search.min.js"></script> <script> SimpleJekyllSearch({ searchInput: document.getElementById('search-input'), resultsContainer: document.getElementById('search-results'), json: '/assets/js/data/search.json', searchResultTemplate: '<div class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-lg-4 pr-lg-4 pl-xl-0 pr-xl-0"> <a href="https://adeeconometrics.github.io/{url}">{title}</a><div class="post-meta d-flex flex-column flex-sm-row text-muted mt-1 mb-1"> {categories} {tags}</div><p>{snippet}</p></div>', noResultsText: '<p class="mt-5">Oops! No result founds.</p>', templateMiddleware: function(prop, value, template) { if (prop === 'categories') { if (value === '') { return `${value}`; } else { return `<div class="mr-sm-4"><i class="far fa-folder fa-fw"></i>${value}</div>`; } } if (prop === 'tags') { if (value === '') { return `${value}`; } else { return `<div><i class="fa fa-tag fa-fw"></i>${value}</div>`; } } } }); </script>
