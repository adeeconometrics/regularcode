<!DOCTYPE html><html lang="en-US" ><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><meta name="generator" content="Jekyll v4.3.4" /><meta property="og:title" content="Stable Diffusion From First Principles" /><meta name="author" content="Dave Amiana" /><meta property="og:locale" content="en_US" /><meta name="description" content="An Overview of Generative Modeling Framework" /><meta property="og:description" content="An Overview of Generative Modeling Framework" /><link rel="canonical" href="https://adeeconometrics.github.io//posts/Stable-Diffusion-From-First-Principles/" /><meta property="og:url" content="https://adeeconometrics.github.io//posts/Stable-Diffusion-From-First-Principles/" /><meta property="og:site_name" content="Dave Amiana" /><meta property="og:type" content="article" /><meta property="article:published_time" content="2022-10-22T00:00:00+08:00" /><meta name="twitter:card" content="summary" /><meta property="twitter:title" content="Stable Diffusion From First Principles" /><meta name="twitter:site" content="@iamdeb25" /><meta name="twitter:creator" content="@Dave Amiana" /><meta name="google-site-verification" content="google-site-verification=28bVbRErS2VwJaonXuu3GbqmRlyNvizt6I00B2kQh88" /> <script type="application/ld+json"> {"@context":"https://schema.org","@type":"BlogPosting","author":{"@type":"Person","name":"Dave Amiana"},"dateModified":"2022-10-22T00:00:00+08:00","datePublished":"2022-10-22T00:00:00+08:00","description":"An Overview of Generative Modeling Framework","headline":"Stable Diffusion From First Principles","mainEntityOfPage":{"@type":"WebPage","@id":"https://adeeconometrics.github.io//posts/Stable-Diffusion-From-First-Principles/"},"url":"https://adeeconometrics.github.io//posts/Stable-Diffusion-From-First-Principles/"}</script><title>Stable Diffusion From First Principles | Dave Amiana</title><link rel="apple-touch-icon" sizes="180x180" href="/assets/img/favicons/apple-touch-icon.png"><link rel="icon" type="image/png" sizes="32x32" href="/assets/img/favicons/favicon-32x32.png"><link rel="icon" type="image/png" sizes="16x16" href="/assets/img/favicons/favicon-16x16.png"><link rel="manifest" href="/assets/img/favicons/site.webmanifest"><link rel="shortcut icon" href="/assets/img/favicons/favicon.ico"><meta name="apple-mobile-web-app-title" content="Dave Amiana"><meta name="application-name" content="Dave Amiana"><meta name="msapplication-TileColor" content="#da532c"><meta name="msapplication-config" content="/assets/img/favicons/browserconfig.xml"><meta name="theme-color" content="#ffffff"><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin="anonymous"><link rel="dns-prefetch" href="https://fonts.gstatic.com"><link rel="preconnect" href="https://www.google-analytics.com" crossorigin="use-credentials"><link rel="dns-prefetch" href="https://www.google-analytics.com"><link rel="preconnect" href="https://www.googletagmanager.com" crossorigin="anonymous"><link rel="dns-prefetch" href="https://www.googletagmanager.com"><link rel="preconnect" href="https://cdn.jsdelivr.net"><link rel="dns-prefetch" href="https://cdn.jsdelivr.net"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.0.0/dist/css/bootstrap.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.11.2/css/all.min.css"><link rel="stylesheet" href="/assets/css/style.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@1.0.1/dist/bootstrap-toc.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/magnific-popup@1.1.0/dist/magnific-popup.min.css"> <script src="https://cdn.jsdelivr.net/npm/jquery@3/dist/jquery.min.js"></script> <script defer src="https://cdn.jsdelivr.net/combine/npm/popper.js@1.15.0,npm/bootstrap@4/dist/js/bootstrap.min.js"></script> <script async src="https://cdn.jsdelivr.net/combine/npm/lozad/dist/lozad.min.js,npm/magnific-popup@1/dist/jquery.magnific-popup.min.js"></script> <script defer src="/assets/js/dist/post.min.js"></script> <script> /* see: <https://docs.mathjax.org/en/latest/options/input/tex.html#tex-options> */ MathJax = { tex: { inlineMath: [ /* start/end delimiter pairs for in-line math */ ['$','$'], ['\\(','\\)'] ], displayMath: [ /* start/end delimiter pairs for display math */ ['$$', '$$'], ['\\[', '\\]'] ] } }; </script> <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script type="text/javascript" id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"> </script> <script defer src="/app.js"></script> <script defer src="https://www.googletagmanager.com/gtag/js?id=G-0M61FBNQ0K"></script> <script> document.addEventListener("DOMContentLoaded", function(event) { window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'G-0M61FBNQ0K'); }); </script><body data-spy="scroll" data-target="#toc"><div id="sidebar" class="d-flex flex-column align-items-end"><div class="profile-wrapper text-center"><div id="avatar"> <a href="/" alt="avatar" class="mx-auto"> <img src="/assets/img/favicons/profile-picture.jpg" alt="avatar" onerror="this.style.display='none'"> </a></div><div class="site-title mt-3"> <a href="/">Dave Amiana</a></div><div class="site-subtitle font-italic">Open-source and Enterprise Software Developer</div></div><ul class="w-100"><li class="nav-item"> <a href="/" class="nav-link"> <i class="fa-fw fas fa-home ml-xl-3 mr-xl-3 unloaded"></i> <span>HOME</span> </a><li class="nav-item"> <a href="/categories/" class="nav-link"> <i class="fa-fw fas fa-stream ml-xl-3 mr-xl-3 unloaded"></i> <span>CATEGORIES</span> </a><li class="nav-item"> <a href="/tags/" class="nav-link"> <i class="fa-fw fas fa-tag ml-xl-3 mr-xl-3 unloaded"></i> <span>TAGS</span> </a><li class="nav-item"> <a href="/archives/" class="nav-link"> <i class="fa-fw fas fa-archive ml-xl-3 mr-xl-3 unloaded"></i> <span>ARCHIVES</span> </a><li class="nav-item"> <a href="/about/" class="nav-link"> <i class="fa-fw fas fa-info-circle ml-xl-3 mr-xl-3 unloaded"></i> <span>ABOUT</span> </a></ul><div class="sidebar-bottom mt-auto d-flex flex-wrap justify-content-center"> <a href="https://github.com/adeeconometrics" aria-label="github" class="order-3" target="_blank" rel="noopener"> <i class="fab fa-github-alt"></i> </a> <a href="https://www.linkedin.com/in/dave-amiana/" aria-label="linkedin" class="order-4" target="_blank" rel="noopener"> <i class="fab fa-linkedin"></i> </a> <a href=" javascript:location.href = 'mailto:' + ['amiana.dave','gmail.com'].join('@')" aria-label="email" class="order-5" > <i class="fas fa-envelope"></i> </a> <span id="mode-toggle-wrapper" class="order-1"> <i class="mode-toggle fas fa-adjust"></i> <script type="text/javascript"> class ModeToggle { static get MODE_KEY() { return "mode"; } static get DARK_MODE() { return "dark"; } static get LIGHT_MODE() { return "light"; } constructor() { if (this.hasMode) { if (this.isDarkMode) { if (!this.isSysDarkPrefer) { this.setDark(); } } else { if (this.isSysDarkPrefer) { this.setLight(); } } } var self = this; /* always follow the system prefers */ this.sysDarkPrefers.addListener(function() { if (self.hasMode) { if (self.isDarkMode) { if (!self.isSysDarkPrefer) { self.setDark(); } } else { if (self.isSysDarkPrefer) { self.setLight(); } } self.clearMode(); } self.updateMermaid(); }); } /* constructor() */ setDark() { $('html').attr(ModeToggle.MODE_KEY, ModeToggle.DARK_MODE); sessionStorage.setItem(ModeToggle.MODE_KEY, ModeToggle.DARK_MODE); } setLight() { $('html').attr(ModeToggle.MODE_KEY, ModeToggle.LIGHT_MODE); sessionStorage.setItem(ModeToggle.MODE_KEY, ModeToggle.LIGHT_MODE); } clearMode() { $('html').removeAttr(ModeToggle.MODE_KEY); sessionStorage.removeItem(ModeToggle.MODE_KEY); } get sysDarkPrefers() { return window.matchMedia("(prefers-color-scheme: dark)"); } get isSysDarkPrefer() { return this.sysDarkPrefers.matches; } get isDarkMode() { return this.mode == ModeToggle.DARK_MODE; } get isLightMode() { return this.mode == ModeToggle.LIGHT_MODE; } get hasMode() { return this.mode != null; } get mode() { return sessionStorage.getItem(ModeToggle.MODE_KEY); } /* get the current mode on screen */ get modeStatus() { if (this.isDarkMode || (!this.hasMode && this.isSysDarkPrefer) ) { return ModeToggle.DARK_MODE; } else { return ModeToggle.LIGHT_MODE; } } updateMermaid() { if (typeof mermaid !== "undefined") { let expectedTheme = (this.modeStatus === ModeToggle.DARK_MODE? "dark" : "default"); let config = { theme: expectedTheme }; /* re-render the SVG â€º <https://github.com/mermaid-js/mermaid/issues/311#issuecomment-332557344> */ $(".mermaid").each(function() { let svgCode = $(this).prev().children().html(); $(this).removeAttr("data-processed"); $(this).html(svgCode); }); mermaid.initialize(config); mermaid.init(undefined, ".mermaid"); } } flipMode() { if (this.hasMode) { if (this.isSysDarkPrefer) { if (this.isLightMode) { this.clearMode(); } else { this.setLight(); } } else { if (this.isDarkMode) { this.clearMode(); } else { this.setDark(); } } } else { if (this.isSysDarkPrefer) { this.setLight(); } else { this.setDark(); } } this.updateMermaid(); } /* flipMode() */ } /* ModeToggle */ let toggle = new ModeToggle(); $(".mode-toggle").click(function() { toggle.flipMode(); }); </script> </span></div></div><div id="topbar-wrapper" class="row justify-content-center topbar-down"><div id="topbar" class="col-11 d-flex h-100 align-items-center justify-content-between"> <span id="breadcrumb"> <span> <a href="/"> Posts </a> </span> <span>Stable Diffusion From First Principles</span> </span> <i id="sidebar-trigger" class="fas fa-bars fa-fw"></i><div id="topbar-title"> Post</div><i id="search-trigger" class="fas fa-search fa-fw"></i> <span id="search-wrapper" class="align-items-center"> <i class="fas fa-search fa-fw"></i> <input class="form-control" id="search-input" type="search" aria-label="search" autocomplete="off" placeholder="Search..."> <i class="fa fa-times-circle fa-fw" id="search-cleaner"></i> </span> <span id="search-cancel" >Cancel</span></div></div><div id="main-wrapper"><div id="main"><div class="row"><div id="post-wrapper" class="col-12 col-lg-11 col-xl-8"><div class="post pl-1 pr-1 pl-sm-2 pr-sm-2 pl-md-4 pr-md-4"><h1 data-toc-skip>Stable Diffusion From First Principles</h1><div class="post-meta text-muted d-flex flex-column"><div> <span class="semi-bold"> Dave Amiana </span> <span class="timeago " data-toggle="tooltip" data-placement="bottom" title="Sat, Oct 22, 2022, 12:00 AM +0800" prep="on" > Oct 22, 2022 <i class="unloaded">2022-10-22T00:00:00+08:00</i> </span></div><div> <span class="readtime" data-toggle="tooltip" data-placement="bottom" title="1854 words">10 min</span></div></div><div class="post-content"><h2 id="an-overview-of-generative-modeling-framework">An Overview of Generative Modeling Framework</h2><p>Generative models have been successfully used for computer vision tasks such as image super-resolution (Saharia <em>et. al.</em>, 2021), text-to-image synthesis (Mirza &amp; Osindero, 2014), and 3D scene rendering (Poole, Jain, Barron, &amp; Mildenhall, 2022). The goal of generative models is to train a probabilistic model that approximates the probability distribution of a dataset.</p><p>The Bayesian framework provides a solid foundation for machine learning by interpreting probability as an expression of belief based on prior knowledge. In this framework, we define a prior that represents our belief about the distribution and update it as new evidence is obtained. The Bayesian approach is used to update the model based on the distribution of new samples drawn from the dataset.</p><p>The prior predictive distribution is defined as the marginal probability of the data in the dataset. If you want to learn more about the application of generative models in computer vision tasks, this is the right article for you.</p><p>The prior predictive distribution is defined as a marginal probability of $x\in X$.</p>\[\begin{aligned} p(x) &amp;= \int_{\theta \in \Theta} p(x, \theta)\ d\theta \\ &amp;= \int_{\theta \in \Theta} p(x|\theta) \times p(\theta)\ d\theta \end{aligned}\]<p>The posterior predictive distribution tell us the probability of the new data $x_t$ given the previous observation $x_{t-1}$.</p>\[p(x_t | x_{t-1}) = \int_{\theta \in \Theta} p(x_t| \theta, x_{t-1}) \times p(\theta|x_{t-1})\ d\theta\]<p>In general, sampling from the true distribution generally not possible for the following reasons: the integral has no closed form solution and (2) the integral is computationally intractable (Blei, Kucukelbir, &amp; McAuliffe, 2018). Given the stated reasons, we are compelled to find a good approximation of the true distribution.</p><p>Early Generative models rely on Markov Chain Monte Carlo (MCMC) sampling methods during training and inference (Bond-Taylor, Leach, Long &amp; Willcocks, 2022). MCMC methods draw samples from a posterior distribution, $x \sim q_{\phi}(x)$ where $\phi$ indexes a family of distributions. MCMC methods such as random walk tends to have long burn-in period which incurs computational overhead. For these reasons, MCMC methods does not scale well with high-dimensional data (Hinton &amp; Sejnowski, 1983; Hinton, Osindero, &amp; Teh, 2006).</p><p>Instead of viewing the inference problem as a random sampling problem drawn from a distribution, variational inference (VI) treats it as an optimization problem (Blei, Kucukelbir, &amp; McAuliffe, 2018). VI define a family of sufficiently large parametric distributions ${p_{\theta} \mid \theta \in \Theta}$ and solve for the parameter $\theta$ that brings the proposal distribution $q_{\phi}$ close to $p_{\theta}$.</p>\[\text{VI} := \min_{\theta} \mathcal{L}(q_{\phi}, p_{\theta})\]<p>Generative models through neural networks dates back to 1980â€™s with its aim to learn data features without supervision (Hinton &amp; Sejnowski, 1983 as cited in Bond-Taylor, Leach, Long &amp; Willcocks, 2022). At the time of its inception, computers were far too limited to meet the computational demands of generative modeling. It the culmination of advancements in developing high-performance hardware, fine-tuned and specialized dataset, and computational techniques for latent-space representation (Bond-Taylor, Leach, Long &amp; Willcocks, 2022) that led to the resurgence of generative models in the scene of deep learning. Deep generative modeling (DGM) involves a deep stacks of hidden layers used to approximate high-dimensional probability distributions (Ruthotto &amp; Haber, 2021). Training DGMs naturally lends itself to an optimization problem where we provide a notion of distance between probability distributions $\mathcal{L}(p_{\theta}, q_{\phi})$ (Grover &amp; Ermon, 2022). VI offers a compelling approach which is scalable, numerically stable, and take advantage of GPUs (Patacchiola, 2022; Ermon, Kuleshov, &amp; Contributors, 2022) at the cost of giving up the search for globally optimal solutions (Ermon, Kuleshov, &amp; Contributors, 2022).</p><p>One way to measure the distance between statistical objects is to measure the Kullback-Leibler (KL) Divergence.</p>\[\begin{aligned} \mathcal{D}_{KL}(p_{\theta}||q_{\phi}) &amp;= \int_{-\infty}^{\infty} p(x) \log \left( \frac{p(x)}{q(x)}\right)\ dx \end{aligned}\]<p>KL-divergence is interpreted as a statistic that distinguish between distribution $p_{\theta}$ and $q_{\phi}$ based from a drawn sample $x \in X$. We can now define VI as an optimization problem that seek to minimize the KL-divergence between distributions as follows:</p>\[\text{VI} := \min \mathcal{D}_{KL}\left(p_{\theta \in Data}(x) || q_{\phi}(x)\right)\]<p>Since explicitly parameterized distributions are limited, we can consider implicitly parameterized distributions and use a neural network $f_{\theta}$ to account for a family of complicated functions.</p><ol><li>Define a naive prior distribution $p$ over a latent random variable $z\in Z$;<li>Define a function approximator that $f_{\theta}(z)$ that approximates the distribution $p(z)$ via parameter $\theta$;<li>Define a function that converts latent function approximation into a simpler distribution over the observable random space $F: f_{\theta}(z) \to q_{\phi}(x)$.</ol><p>Using this approach we obtain a flexible generative model that is easy to sample.</p><p>We can use KL-divergence as our loss function. But KL-divergence still arrives at an intractable state as shown below:</p>\[\begin{aligned} \mathcal{D}_{KL} \big( q(\mathbf{z}) || p(\mathbf{z} | \mathbf{x}) \big) &amp;= \int q(\mathbf{z}) \log \frac{q(\mathbf{z})}{p(\mathbf{z} | \mathbf{x})} d\mathbf{z}\\ &amp;= \int q(\mathbf{z}) \big( \log q(\mathbf{z}) - \log p(\mathbf{z} | \mathbf{x}) \big) d\mathbf{z}\\ &amp;= \int q(\mathbf{z}) \log q(\mathbf{z}) - q(\mathbf{z}) \log p(\mathbf{z} | \mathbf{x}) d\mathbf{z}\\ &amp;= \int q(\mathbf{z}) \log q(\mathbf{z}) d\mathbf{z} - \int q(\mathbf{z}) \log p(\mathbf{z} | \mathbf{x}) d\mathbf{z}\\ \end{aligned}\]<p>Applying the definition of expectation over integrals $\mathbb{E}[X] = \int_{x\in X} x \cdot f(x)\ dx$:</p>\[\begin{aligned} \mathcal{D}_{KL} \big( q(\mathbf{z}) || p(\mathbf{z} | \mathbf{x}) \big) &amp;= \mathbb{E}_{q} \big[ \log q(\mathbf{z}) \big] - \mathbb{E}_{q} \big[ \log p(\mathbf{z} | \mathbf{x}) \big] &amp;\\ &amp;= \mathbb{E}_{q} \big[ \log q(\mathbf{z}) \big] - \mathbb{E}_{q} \bigg[ \log \frac{p(\mathbf{x}, \mathbf{z}) }{p(\mathbf{x})} \bigg]\\ &amp;= \mathbb{E}_{q} \big[ \log q(\mathbf{z}) \big] - \mathbb{E}_{q} \big[ \log p(\mathbf{x}, \mathbf{z}) - \log p(\mathbf{x}) \big]\\ &amp;= \mathbb{E}_{q} \big[ \log q(\mathbf{z}) - \log p(\mathbf{x}, \mathbf{z}) \big] + \mathbb{E}_{q} \big[ \log p(\mathbf{x}) \big]\\ &amp;= \mathbb{E}_{q} \big[ \log q(\mathbf{z}) - \log p(\mathbf{x}, \mathbf{z}) \big] + \underbrace{\log p(\mathbf{x})}_{\text{intractable}}\\ \end{aligned}\]<p>Training a neural network involves a loss function $\mathcal{L}$ which measures the direction we adjust our gradients. To remedy this, we derive the Evidence Lower Bound (ELBO) from $\mathcal{D}_{KL}$. The key insight behind ELBO is to group the intractable part of the derived equation and frame the problem as a maximization problem:</p>\[\begin{aligned} \mathcal{D}_{KL}(q(\textbf{z}) || p(\textbf{x} | \textbf{z})) &amp;= \mathbb{E}_{q} \big[ \log q(\mathbf{z}) - \log p(\mathbf{x}, \mathbf{z}) \big] + \log p(\mathbf{x}) \\ \mathbb{E}_{q} \big[ \log q(\mathbf{z}) - \log p(\mathbf{x}, \mathbf{z}) \big] &amp;= \log p(\mathbf{x})-\mathcal{D}_{KL}(q(\textbf{z}) || p(\textbf{x} | \textbf{z})) \\ \text{ELBO}(q) &amp;= \mathbb{E}_{q} \big[ \log q(\mathbf{z}) - \log p(\mathbf{x}, \mathbf{z}) \big]\\ &amp; = \mathbb{E}_{q} \bigg[ \log \frac{p(\mathbf{x}, \mathbf{z})}{q(\mathbf{z})} \bigg]. \end{aligned}\]<p>In this frame, by maximizing ELBO, we maximize the evidence $p(\mathbf{x})$ and minimize the KL-divergence.</p><p>Now that we define a probabilistic framework for generative modeling, we move our discussion to a specific type of generative model called Diffusion model.</p><h2 id="diffusion-based-generative-models">Diffusion-based Generative Models</h2><p>Diffusion-based generative models are inspired by non-equilibrium thermodynamics (Ho, Jain, &amp; Abbeel, 2020). This approach introduce a diffusion process of adding random noise to an image via a forward process and training a neural network to denoise the image through a reverse process.</p><p>The diffusion process is a Markov Chain summarized as:</p>\[\begin{aligned} q(x_t | x_{t-1}) &amp;= \mathcal{N_{\theta}}\left(x_t\right) \\ q(x_{1:T}|x_0) &amp;= \prod_{t=1}^T q(x_t | x_{t-1}) \end{aligned}\]<p>The forward process adds noise from the noise kernel $\mathcal{N}$. Gaussian Noise is favored for its simplicity and additive property. The reverse process then attempt to predict the added noise and recover the original image. Iteratively adding Gaussian Noise at $x_t$ as $t \to \infty$ is equivalent to an isotropic Gaussian Distribution.</p><h3 id="denoising-diffusion-probabilistic-model-ddpm">Denoising Diffusion Probabilistic Model (DDPM)</h3><p>Ho, Jain, and Abbel (2020) introduced a promising approach for generative modeling called DDPM. As mentioned, the model mainly revolves around forward diffusion process and reverse diffusion process.</p><p>During training, the forward diffusion process takes the image $x_{t:T}$ to a standard Gaussian $\mathcal{N}(0, \text{I})$. At each step of the Markov Process, add a Gaussian noise. This process will produce a latent variable $x_t$ with distribution $q(x_t\mid x_{t-1})$. This process is summarized as:</p>\[\begin{aligned} q(x_t | x_{t-1}) &amp;= \mathcal{N}\left(x_t; \mu_t = \sqrt{1-\beta_t}x_{t-1}, \sigma^2_t = \beta_t \textbf{I} \right) \\ q(x_{1:T}|x_0) &amp;= \prod_{t=1}^T q(x_t | x_{t-1}) \end{aligned}\]<p>At a sufficiently large step size, the image is assumed approximate a Gaussian Kernel $x_T \sim \mathcal{N}(x_t; \textbf{0,I})$.</p><p>The reverse diffusion process attempts to recover the image from information loss introduced by the noise kernel. The reverse process is also a Markov Process summarized as a set of parametric equations:</p>\[\begin{aligned} p(x_T) &amp;= \mathcal{N}(x_T; \textbf{0,I}) \\ p_{\theta}(x_{t-1} | x_t) &amp;= \mathcal{N}(x_{t-1}; \mu_{\theta}(x_t, t), \sigma^2_t\textbf{I}). \end{aligned}\]<p>In the reverse process, we recognize that $x_{x\to \infty} \approx \mathcal{N}(\mathbf{0}, \mathbf{I})$. For training our model to predict the added noise at timestep $t$, we parameterize $\mu$ and turn it into a neural network that predicts the noise.</p><p>Training DDPM usually involve a reweighted variant of ELBO on $p(x)$.</p>\[\mathcal{L}_{DM} := \mathbb{E}_{x,\epsilon \sim \mathcal{N}(0,1),t} \big[ ||\epsilon - \epsilon_{\theta}(x,t) ||^2_2 \big]\]<p>In this process, we sample $x$ and a noise $\epsilon$ from the standard Gaussian kernel as well as the timestep $t$. Then we minimize the Mean Square Error (MSE) loss between the known noise $\epsilon$ and the predicted noise given by the model $\epsilon_{\theta}$.</p><h3 id="latent-diffusion-model-ldm">Latent Diffusion Model (LDM)</h3><p>Rombach, Blattmann, Lorenz, Esser, &amp; Ommer (2022) introduced LDM. Their model, Stable Diffusion (SD), improved the computational cost of running diffusion models on high-dimensional dataset such as image by obtaining a latent space representation of the sample in question.</p><p>For training LDM, we sample from the latent space $z \in Z$.</p>\[\mathcal{L}_{LDM} := \mathbb{E}_{\varepsilon(x), \epsilon \sim \mathcal{N}(0,1),t} \big[ ||\epsilon - \epsilon_{\theta}(z_t,t) ||^2_2 \big]\]<p>The model $\varepsilon(x)$ maps to a latent space with significantly dimensionality. This approach enable SD to run more efficiently over Googleâ€™s Imagen (Saharia <em>et al.</em>, 2022) and OpenAIâ€™s Dall-E 2 (Ramesh, Dhariwal, Nichol, Chu, &amp; Chen, 2022).</p><hr /><h2 id="references">References</h2><ol><li>Saharia, C., Ho, J., Chan, W., Salimans, T., Fleet, D. J., &amp; Norouzi, M. (2021). Image Super-Resolution via Iterative Refinement. <em>arXiv</em>. https://doi.org/10.48550/arXiv.2104.07636<li>Mirza, M., &amp; Osindero, S. (2014). Conditional Generative Adversarial Nets. <em>arXiv</em>. https://doi.org/10.48550/arXiv.1411.1784<li>Poole, B., Jain, A., Barron, J. T., &amp; Mildenhall, B. (2022). DreamFusion: Text-to-3D using 2D Diffusion. <em>arXiv</em>. https://doi.org/10.48550/arXiv.2209.14988<li>Ghahramani, Z. (2015). Probabilistic machine learning and artificial intelligence. Nature, 521(7553), 452â€“459. doi:10.1038/nature14541<li>Hinton, G.E., &amp; Sejnowski, T.J. (1983). Optimal Perceptual Inference.<li>Hinton, G. E., Osindero, S., &amp; Teh, Y. W. (2006). A fast learning algorithm for deep belief nets.Â <em>Neural computation</em>,Â <em>18</em>(7), 1527-1554.<li>Bond-Taylor, S., Leach, A., Long, Y., &amp; Willcocks, C. G. (2021). Deep generative modelling: A comparative review of VAEs, GANs, normalizing flows, energy-based and autoregressive models. arXiv preprint arXiv:2103.04922.<li>Blei, D. M., Kucukelbir, A., &amp; McAuliffe, J. D. (2017). Variational inference: A review for statisticians.Â <em>Journal of the American statistical Association</em>,Â <em>112</em>(518), 859-877.<li>Grover, A. &amp; Ermon, S. (2022). Notes on Deep Generative Models. Stanford. https://github.com/deepgenerativemodels/notes.<li>Ruthotto, L., &amp; Haber, E. (2021).Â <em>An introduction to deep generative modeling. GAMM-Mitteilungen, 44(2).</em>Â doi:10.1002/gamm.202100008.<li>M. Patacchiola (2021). Evidence, KL-divergence, and ELBO. https://mpatacchiola.github.io/blog/2021/01/25/intro-variational-inference.html<li>Ermon, S., Kuleshov, V. &amp; Contributors (2022). Variational Inference. Stanford. https://ermongroup.github.io/cs228-notes/<li>Ho, J., Jain, A., &amp; Abbeel, P. (2020). Denoising diffusion probabilistic models.Â <em>Advances in Neural Information Processing Systems</em>,Â <em>33</em>, 6840-6851.<li>Rombach, R., Blattmann, A., Lorenz, D., Esser, P., &amp; Ommer, B. (2022). High-resolution image synthesis with latent diffusion models. InÂ <em>Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</em>Â (pp. 10684-10695).<li>Saharia, C., Chan, W., Saxena, S., Li, L., Whang, J., Denton, E., â€¦ &amp; Norouzi, M. (2022). Photorealistic Text-to-Image Diffusion Models with Deep Language Understanding.Â <em>arXiv preprint arXiv:2205.11487</em>.<li>Ramesh, A., Dhariwal, P., Nichol, A., Chu, C., &amp; Chen, M. (2022). Hierarchical text-conditional image generation with clip latents.Â <em>arXiv preprint arXiv:2204.06125</em>.</ol></div><div class="post-tail-wrapper text-muted"><div class="post-meta mb-3"> <i class="far fa-folder-open fa-fw mr-1"></i> <a href='/categories/programming/'>Programming</a>, <a href='/categories/computer-science/'>Computer Science</a>, <a href='/categories/diffusion-model/'>Diffusion Model</a>, <a href='/categories/ai/'>AI</a></div><div class="post-tags"> <i class="fa fa-tags fa-fw mr-1"></i> <a href="/tags/programming/" class="post-tag no-text-decoration" >programming</a> <a href="/tags/computer-science/" class="post-tag no-text-decoration" >Computer Science</a></div><div class="post-tail-bottom d-flex justify-content-between align-items-center mt-3 pt-5 pb-2"><div class="license-wrapper"> This post is licensed under <a href="https://creativecommons.org/licenses/by/4.0/">CC BY 4.0</a> by the author.</div><div class="share-wrapper"> <span class="share-label text-muted mr-1">Share</span> <span class="share-icons"> <a href="https://twitter.com/intent/tweet?text=Stable Diffusion From First Principles - Dave Amiana&url=https://adeeconometrics.github.io//posts/Stable-Diffusion-From-First-Principles/" data-toggle="tooltip" data-placement="top" title="Twitter" target="_blank" rel="noopener" aria-label="Twitter"> <i class="fa-fw fab fa-twitter"></i> </a> <a href="https://www.facebook.com/sharer/sharer.php?title=Stable Diffusion From First Principles - Dave Amiana&u=https://adeeconometrics.github.io//posts/Stable-Diffusion-From-First-Principles/" data-toggle="tooltip" data-placement="top" title="Facebook" target="_blank" rel="noopener" aria-label="Facebook"> <i class="fa-fw fab fa-facebook-square"></i> </a> <a href="https://telegram.me/share?text=Stable Diffusion From First Principles - Dave Amiana&url=https://adeeconometrics.github.io//posts/Stable-Diffusion-From-First-Principles/" data-toggle="tooltip" data-placement="top" title="Telegram" target="_blank" rel="noopener" aria-label="Telegram"> <i class="fa-fw fab fa-telegram"></i> </a> <i class="fa-fw fas fa-link small" onclick="copyLink()" data-toggle="tooltip" data-placement="top" title="Copy link"></i> </span></div></div></div></div></div><div id="panel-wrapper" class="col-xl-3 pl-2 text-muted topbar-down"><div class="access"><div id="access-lastmod" class="post"> <span>Recent Update</span><ul class="post-content pl-0 pb-1 ml-1 mt-2"><li><a href="/posts/On-Pointer-Types/">On Pointer Types</a><li><a href="/posts/Pointers-and-References-Design-Goals-and-Use-Cases/">Pointers and References: Design Goals and Use Cases</a><li><a href="/posts/Unique-Reference/">Unique References</a><li><a href="/posts/Shared-Reference/">Shared References</a><li><a href="/posts/Weak-Reference/">Weak References</a></ul></div><div id="access-tags"> <span>Trending Tags</span><div class="d-flex flex-wrap mt-3 mb-1 mr-3"> <a class="post-tag" href="/tags/computer-science/">Computer Science</a> <a class="post-tag" href="/tags/programming/">programming</a> <a class="post-tag" href="/tags/c/">C++</a> <a class="post-tag" href="/tags/data-structures/">Data Structures</a> <a class="post-tag" href="/tags/programming/">Programming</a> <a class="post-tag" href="/tags/algorithms/">Algorithms</a> <a class="post-tag" href="/tags/ownership-semantics/">Ownership Semantics</a> <a class="post-tag" href="/tags/ai/">AI</a> <a class="post-tag" href="/tags/c/">C#</a> <a class="post-tag" href="/tags/java/">Java</a></div></div></div><script src="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@1.0.1/dist/bootstrap-toc.min.js"></script><div id="toc-wrapper" class="pl-0 pr-4 mb-5"> <span class="pl-3 pt-2 mb-2">Contents</span><nav id="toc" data-toggle="toc"></nav></div></div></div><div class="row"><div class="col-12 col-lg-11 col-xl-8"><div id="post-extend-wrapper" class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-md-4 pr-md-4"><div id="related-posts" class="mt-5 mb-2 mb-sm-4"><h3 class="pt-2 mt-1 mb-4 ml-1" data-toc-skip>Further Reading</h3><div class="card-deck mb-4"><div class="card"> <a href="/posts/On-Pointer-Types/"><div class="card-body"> <span class="timeago small" > Aug 12, 2021 <i class="unloaded">2021-08-12T00:00:00+08:00</i> </span><h3 class="pt-0 mt-1 mb-3" data-toc-skip>On Pointer Types</h3><div class="text-muted small"><p> In this article, I aim to introduce the concept and motivation behind using pointers. There are breeds of C++ developers that only use smart pointers for safety reasons, others that only use raw po...</p></div></div></a></div><div class="card"> <a href="/posts/Pointers-and-References-Design-Goals-and-Use-Cases/"><div class="card-body"> <span class="timeago small" > Aug 12, 2021 <i class="unloaded">2021-08-12T00:00:00+08:00</i> </span><h3 class="pt-0 mt-1 mb-3" data-toc-skip>Pointers and References: Design Goals and Use Cases</h3><div class="text-muted small"><p> At first, it seems that C++ makes things more complicated by introducing yet another layer of abstraction. References seem to encapsulate the same set of functionalities as pointers. Both of these ...</p></div></div></a></div><div class="card"> <a href="/posts/Unique-Reference/"><div class="card-body"> <span class="timeago small" > Aug 17, 2021 <i class="unloaded">2021-08-17T00:00:00+08:00</i> </span><h3 class="pt-0 mt-1 mb-3" data-toc-skip>Unique References</h3><div class="text-muted small"><p> Our previous discussion explores the anatomy of pointer types in C and C++ on par with hinting nuances of reference semantics. We discussed the use cases of raw pointers and smart pointers in moder...</p></div></div></a></div></div></div><div class="post-navigation d-flex justify-content-between"> <a href="/posts/Design-Principles-Of-Data-Structures-Library/" class="btn btn-outline-primary" prompt="Older"><p>Design Principles of Data Structures Library</p></a> <span class="btn btn-outline-primary disabled" prompt="Newer"><p>-</p></span></div></div></div></div><footer class="d-flex w-100 justify-content-center"><div class="d-flex justify-content-between align-items-center text-muted"><div class="footer-left"><p class="mb-0"> Â© 2024 <a href="https://twitter.com/iamdeb25">Dave Amiana</a>.</p></div><div class="footer-right"><p class="mb-0"> Powered by <a href="https://jekyllrb.com" target="_blank" rel="noopener">Jekyll</a> with <a href="https://github.com/cotes2020/jekyll-theme-chirpy" target="_blank" rel="noopener">Chirpy</a> theme.</p></div></div></footer></div><div id="search-result-wrapper" class="d-flex justify-content-center unloaded"><div class="col-12 col-sm-11 post-content"><div id="search-hints"><h4 class="text-muted mb-4">Trending Tags</h4><a class="post-tag" href="/tags/computer-science/">Computer Science</a> <a class="post-tag" href="/tags/programming/">programming</a> <a class="post-tag" href="/tags/c/">C++</a> <a class="post-tag" href="/tags/data-structures/">Data Structures</a> <a class="post-tag" href="/tags/programming/">Programming</a> <a class="post-tag" href="/tags/algorithms/">Algorithms</a> <a class="post-tag" href="/tags/ownership-semantics/">Ownership Semantics</a> <a class="post-tag" href="/tags/ai/">AI</a> <a class="post-tag" href="/tags/c/">C#</a> <a class="post-tag" href="/tags/java/">Java</a></div><div id="search-results" class="d-flex flex-wrap justify-content-center text-muted mt-3"></div></div></div></div><script src="https://cdn.jsdelivr.net/npm/mermaid@8/dist/mermaid.min.js"></script> <script> $(function() { let initTheme = "default"; if ($("html[mode=dark]").length > 0 || ($("html[mode]").length == 0 && window.matchMedia("(prefers-color-scheme: dark)").matches ) ) { initTheme = "dark"; } let mermaidConf = { theme: initTheme /* <default|dark|forest|neutral> */ }; /* Markdown converts to HTML */ $("pre").has("code.language-mermaid").each(function() { let svgCode = $(this).children().html(); $(this).addClass("unloaded"); $(this).after(`<div class=\"mermaid\">${svgCode}</div>`); }); mermaid.initialize(mermaidConf); }); </script><div id="mask"></div><a id="back-to-top" href="#" aria-label="back-to-top" class="btn btn-lg btn-box-shadow" role="button"> <i class="fas fa-angle-up"></i> </a> <script src="https://cdn.jsdelivr.net/npm/simple-jekyll-search@1.7.3/dest/simple-jekyll-search.min.js"></script> <script> SimpleJekyllSearch({ searchInput: document.getElementById('search-input'), resultsContainer: document.getElementById('search-results'), json: '/assets/js/data/search.json', searchResultTemplate: '<div class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-lg-4 pr-lg-4 pl-xl-0 pr-xl-0"> <a href="https://adeeconometrics.github.io/{url}">{title}</a><div class="post-meta d-flex flex-column flex-sm-row text-muted mt-1 mb-1"> {categories} {tags}</div><p>{snippet}</p></div>', noResultsText: '<p class="mt-5">Oops! No result founds.</p>', templateMiddleware: function(prop, value, template) { if (prop === 'categories') { if (value === '') { return `${value}`; } else { return `<div class="mr-sm-4"><i class="far fa-folder fa-fw"></i>${value}</div>`; } } if (prop === 'tags') { if (value === '') { return `${value}`; } else { return `<div><i class="fa fa-tag fa-fw"></i>${value}</div>`; } } } }); </script>
